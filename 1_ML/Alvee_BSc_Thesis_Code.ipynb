{"cells":[{"cell_type":"markdown","source":["# **Importing Libraries**"],"metadata":{"id":"DP9WzjHKH7ff"}},{"cell_type":"markdown","source":["First, All the necessary libraries are to be imported "],"metadata":{"id":"Ti794GKIIBsg"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"gXTlOgRWcTZB","executionInfo":{"status":"ok","timestamp":1652940376670,"user_tz":-360,"elapsed":4022,"user":{"displayName":"Alvee Hannan","userId":"12340570370596767258"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from pandas import read_csv\n","import math\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from tensorflow.keras.models import load_model\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score\n","import seaborn as sns\n","from datetime import datetime\n","from sklearn.model_selection import TimeSeriesSplit\n","from keras.callbacks import LearningRateScheduler\n","from sklearn.model_selection import GridSearchCV\n","from keras.constraints import maxnorm\n","import joblib\n","from numpy.random import seed\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn import metrics\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","source":["Setting Random seed value"],"metadata":{"id":"14h98SbmIrGw"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"ZU9R4n3EcdIq","executionInfo":{"status":"ok","timestamp":1652940379507,"user_tz":-360,"elapsed":429,"user":{"displayName":"Alvee Hannan","userId":"12340570370596767258"}}},"outputs":[],"source":["seed(1)\n","tf.random.set_seed=(1)"]},{"cell_type":"markdown","source":["# **Define number of variables**"],"metadata":{"id":"0ABTuxbhJCgQ"}},{"cell_type":"markdown","source":["For Input combination 1, variables chosen are Tp and WL;         \n","For Input combination 2, variables chosen are Tp, Swvl1,2,3 and WL;         \n","For Input combination 3, variables chosen are Tp, Swvl1,2,3, Tcrw and WL;       \n","For Input combination 4, variables chosen are Tp, Swvl1,2,3, Tcrw, Tcwv and WL"],"metadata":{"id":"iTpGjShBKYJm"}},{"cell_type":"code","source":["comb=1\n"],"metadata":{"id":"615YAG7qqNf-","executionInfo":{"status":"ok","timestamp":1652940384164,"user_tz":-360,"elapsed":479,"user":{"displayName":"Alvee Hannan","userId":"12340570370596767258"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SOZEuv9VTTho","executionInfo":{"status":"ok","timestamp":1652940386045,"user_tz":-360,"elapsed":6,"user":{"displayName":"Alvee Hannan","userId":"12340570370596767258"}},"colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"f84b306c-117c-4fc5-a653-fe5a362bdf8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input Combination:  1\n","number of variables:  2\n"]}],"source":["if comb==1: var,vars=2,\"Tp\"\n","elif comb==2: var,vars=5,\"TpSwvl\"\n","elif comb==3: var,vars=6,\"TpSwvlTcrw\"\n","elif comb==4: var,vars=7,\"TpSwvlTcrw\"\n","\n","print(\"Input Combination: \",comb)\n","print(\"number of variables: \", var)"]},{"cell_type":"markdown","metadata":{"id":"Gu1nKaSwx2mZ"},"source":["# **Data Import**"]},{"cell_type":"markdown","source":["First, we must mount the colab file to the drive containing our data. This will require google sign in"],"metadata":{"id":"HsNOA1qPMWJR"}},{"cell_type":"markdown","source":["For Google sign-in please use the following credentials:\n","\n","email: ***bscthesis016@gmail.com***\n","\n","Password: ***Thesis016***"],"metadata":{"id":"EZONx8zzRiCY"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26033,"status":"ok","timestamp":1652902434737,"user":{"displayName":"Alvee Hannan","userId":"12340570370596767258"},"user_tz":-360},"id":"9fjtXhp2cfWX","outputId":"5a33d123-2fe8-41d7-bfa5-ee4228798515"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7tlexXpucxdI"},"outputs":[],"source":["dataframe = pd.read_excel(\"/content/drive/MyDrive/Thesis/data.xlsx\")\n","#df = pd.read_excel(\"data.xlsx\")\n","dataframe"]},{"cell_type":"markdown","metadata":{"id":"W75Mp7Lex8Jp"},"source":["# **Data Processing For ANN, Random Forest, CatBoost**"]},{"cell_type":"markdown","source":["Now we will have to process the data for using in our models. We start by setting the dates as index"],"metadata":{"id":"QBwP1RTJNLvf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lzHcjHl636Ax"},"outputs":[],"source":["df=dataframe.set_index('Date')"]},{"cell_type":"markdown","source":["Then we select our list of variables by columns from the dataframe."],"metadata":{"id":"wyvpHX7UNxH2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kMzQh3vl4Kb6"},"outputs":[],"source":["cols = list(df)[0:var]\n","print(cols)"]},{"cell_type":"markdown","source":["now we create dataframe df containing only the variables to be used"],"metadata":{"id":"5ViHJe_bOCNW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"g5fVf2Adel85"},"outputs":[],"source":["df = df[cols].astype(float) #Convert values to float\n","df"]},{"cell_type":"markdown","source":["**Declaraion: All variable names from here onwards will contain a number. the number is indicative of the lead time**"],"metadata":{"id":"sNmMzRhxRmjt"}},{"cell_type":"markdown","source":["Now, for different lead times, we prepare the input and target dataset"],"metadata":{"id":"4ngqPKY3OYZ_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-NzA1lQQgXOX"},"outputs":[],"source":["dfX1 = df[:-1]\n","dfX3 = df[:-3]\n","dfX5 = df[:-5]\n","dfX7 = df[:-7]"]},{"cell_type":"markdown","source":["Now we see that our input dataset for 7 day lead spans from 1/1/2007 to 24/12/2020"],"metadata":{"id":"wvnayfhZPT7W"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"N_zNDht9CMoY"},"outputs":[],"source":["dfX7"]},{"cell_type":"markdown","source":["Checking to see if the remaining input datasets are in proper shape"],"metadata":{"id":"_vBEbnckPsF1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jcikh4-62wxV"},"outputs":[],"source":["print(\"Shape of dfX1: {}\".format(dfX1.shape))\n","print(\"Shape of dfX3: {}\".format(dfX3.shape))\n","print(\"Shape of dfX5: {}\".format(dfX5.shape))\n","print(\"Shape of dfX7: {}\".format(dfX7.shape))"]},{"cell_type":"markdown","source":["Repeating the procedure for our target dataset we get:"],"metadata":{"id":"Y22oWb39P65W"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghVr1EUe3E8o"},"outputs":[],"source":["df_Y=df[['WL']]\n","dfY1=df_Y[1:]\n","dfY3=df_Y[3:]\n","dfY5=df_Y[5:]\n","dfY7=df_Y[7:]"]},{"cell_type":"markdown","source":["Now we see that the output dataset for 7day lead spans from 8/1/2007 to 31/12/2020"],"metadata":{"id":"EVpJnn4PQHmP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AXy99_xFCYnj"},"outputs":[],"source":["dfY7"]},{"cell_type":"markdown","source":["Checking the shapes for remaining lead times:"],"metadata":{"id":"z8I-87d5QXYP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IoSQ9P4Z8SZr"},"outputs":[],"source":["print(\"Shape of dfY1: {}\".format(dfY1.shape))\n","print(\"Shape of dfY3: {}\".format(dfY3.shape))\n","print(\"Shape of dfY5: {}\".format(dfY5.shape))\n","print(\"Shape of dfY7: {}\".format(dfY7.shape))"]},{"cell_type":"markdown","source":["Now we split the datasets into training, validation and testing sets, with 50%, 20% and 30% data respectively "],"metadata":{"id":"xJtjl7HSQhwt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6HhXWjqf7PW1"},"outputs":[],"source":["train_size1 = int(len(dfX1) * 0.5)\n","val_size1 = int(len(dfX1) * 0.2)\n","test_size1 = len(dfX1) - train_size1 -val_size1\n","trainX1, valX1, testX1 = dfX1[0:train_size1], dfX1[train_size1:-test_size1], dfX1[-test_size1:]\n","trainY1, valY1, testY1 = dfY1[0:train_size1], dfY1[train_size1:-test_size1], dfY1[-test_size1:]\n","\n","train_size3 = int(len(dfX3) * 0.5)\n","val_size3 = int(len(dfX3) * 0.2)\n","test_size3 = len(dfX3) - train_size3 -val_size3\n","trainX3, valX3, testX3 = dfX3[0:train_size3], dfX3[train_size3:-test_size3], dfX3[-test_size3:]\n","trainY3, valY3, testY3 = dfY3[0:train_size3], dfY3[train_size3:-test_size3], dfY3[-test_size3:]\n","\n","train_size5 = int(len(dfX5) * 0.5)\n","val_size5 = int(len(dfX5) * 0.2)\n","test_size5 = len(dfX5) - train_size5 -val_size5\n","trainX5, valX5, testX5 = dfX5[0:train_size5], dfX5[train_size5:-test_size5], dfX5[-test_size5:]\n","trainY5, valY5, testY5 = dfY5[0:train_size5], dfY5[train_size5:-test_size5], dfY5[-test_size5:]\n","\n","train_size7 = int(len(dfX7) * 0.5)\n","val_size7 = int(len(dfX7) * 0.2)\n","test_size7 = len(dfX7) - train_size7 -val_size7\n","trainX7, valX7, testX7 = dfX7[0:train_size7], dfX7[train_size7:-test_size7], dfX7[-test_size7:]\n","trainY7, valY7, testY7 = dfY7[0:train_size7], dfY7[train_size7:-test_size7], dfY7[-test_size7:]"]},{"cell_type":"markdown","source":["Now we check the shape of train and test size samples for all lead times"],"metadata":{"id":"aPhvIbMsSSlO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7glwqyAYpRy9"},"outputs":[],"source":["print(\"Shape of training set X1: {}\".format(trainX1.shape))\n","print(\"Shape of test set X1: {}\".format(testX1.shape))\n","print(\"Shape of training set Y1: {}\".format(trainY1.shape))\n","print(\"Shape of test set Y1: {}\".format(testY1.shape))\n","\n","print(\"Shape of training set X3: {}\".format(trainX3.shape))\n","print(\"Shape of test set X3: {}\".format(testX3.shape))\n","print(\"Shape of training set Y3: {}\".format(trainY3.shape))\n","print(\"Shape of test set Y3: {}\".format(testY3.shape))\n","\n","print(\"Shape of training set X5: {}\".format(trainX5.shape))\n","print(\"Shape of test set X5: {}\".format(testX5.shape))\n","print(\"Shape of training set Y5: {}\".format(trainY5.shape))\n","print(\"Shape of test set Y5: {}\".format(testY5.shape))\n","\n","print(\"Shape of training set X7: {}\".format(trainX7.shape))\n","print(\"Shape of test set X7: {}\".format(testX7.shape))\n","print(\"Shape of training set Y7: {}\".format(trainY7.shape))\n","print(\"Shape of test set Y7: {}\".format(testY7.shape))\n","\n","\n"]},{"cell_type":"markdown","source":["***Data Processing complete, now moving on to model building***"],"metadata":{"id":"5x7cnf3dSeZd"}},{"cell_type":"markdown","metadata":{"id":"mIlglUImyFzm"},"source":["# **ANN**"]},{"cell_type":"markdown","source":["If the models have already been develpoed, We can just import the saved models and move on to prediction. If not, then we have to train the models"],"metadata":{"id":"tiRwwrflcSmd"}},{"cell_type":"markdown","metadata":{"id":"-4eSbhC_9SbF"},"source":["## **Import Models**"]},{"cell_type":"markdown","source":["we import 4 models for 4 different lead times"],"metadata":{"id":"SIFX87ZXc352"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"s58UpVeu9Rlx"},"outputs":[],"source":["ANN1 = load_model('/content/drive/MyDrive/Thesis/SavedModels/\"+vars+\"/ANN/ANN1.h5')\n","\n","ANN3 = load_model('/content/drive/MyDrive/Thesis/SavedModels/\"+vars+\"/ANN/ANN3.h5')\n","\n","ANN5 = load_model('/content/drive/MyDrive/Thesis/SavedModels/\"+vars+\"/ANN/ANN5.h5')\n","\n","ANN7 = load_model('/content/drive/MyDrive/Thesis/SavedModels/\"+vars+\"/ANN/ANN7.h5')"]},{"cell_type":"markdown","metadata":{"id":"mELZXJHj8NsT"},"source":["## **BUilding models**"]},{"cell_type":"markdown","source":["For building the DNN models, we define the model as sequential. then we add 6 dense layers with 64 neurons each, with activation function set to ReLU. the first layer contains the input variables and has the shape as the variables. The last dense layer was set with a single output.\n","\n","finally, the models were compiled with loss function set to rmse and optimizer set to adam."],"metadata":{"id":"u7vLRxIac-O0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y4Dnyb21wV9X"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dAvaKvgypU7s"},"outputs":[],"source":["#ANN model for 1 day Lead\n","\n","print('Build deep model...')\n","\n","ANN1 = Sequential()\n","ANN1.add(Dense(64, input_shape=(var,), activation='relu')) #12\n","#ANN1.add(Dropout(0.2))\n","ANN1.add(Dense(64, activation='relu'))  #8\n","#ANN1.add(Dropout(0.2))\n","ANN1.add(Dense(64,activation='relu'))\n","ANN1.add(Dense(64,activation='relu'))\n","ANN1.add(Dense(64,activation='relu'))\n","ANN1.add(Dense(64,activation='relu'))\n","ANN1.add(Dense(1))\n","ANN1.compile(loss='mean_squared_error', optimizer='Adam', metrics = [tf.keras.metrics.MeanSquaredError()])\n","print(ANN1.summary())"]},{"cell_type":"markdown","source":["The same was repeated for all lead times."],"metadata":{"id":"srz3z481eaBP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQMzUmnO6EqG"},"outputs":[],"source":["#ANN model for 3 day Lead\n","\n","print('Build deep model...')\n","\n","ANN3 = Sequential()\n","ANN3.add(Dense(64, input_shape=(var,), activation='relu'))\n","#ANN3.add(Dropout(0.2))\n","ANN3.add(Dense(64, activation='relu')) \n","#ANN3.add(Dropout(0.2))\n","ANN3.add(Dense(64,activation='relu'))\n","ANN3.add(Dense(64,activation='relu'))\n","ANN3.add(Dense(64,activation='relu'))\n","ANN3.add(Dense(64,activation='relu'))\n","ANN3.add(Dense(1))\n","ANN3.compile(loss='mean_squared_error', optimizer='Adam', metrics = [tf.keras.metrics.MeanSquaredError()])\n","print(ANN3.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sb2nTJmj6H3Z"},"outputs":[],"source":["#ANN model for 5 day Lead\n","\n","print('Build deep model...')\n","\n","ANN5 = Sequential()\n","ANN5.add(Dense(64, input_shape=(var,), activation='relu')) \n","#ANN5.add(Dropout(0.2))\n","ANN5.add(Dense(64, activation='relu')) \n","#ANN5.add(Dropout(0.2))\n","ANN5.add(Dense(64,activation='relu'))\n","ANN5.add(Dense(64,activation='relu'))\n","ANN5.add(Dense(64,activation='relu'))\n","ANN5.add(Dense(64,activation='relu'))\n","ANN5.add(Dense(1))\n","ANN5.compile(loss='mean_squared_error', optimizer='Adam', metrics = [tf.keras.metrics.MeanSquaredError()])\n","print(ANN5.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AMPgODFS6H0l"},"outputs":[],"source":["#ANN model for 7 day Lead\n","\n","print('Build deep model...')\n","\n","ANN7 = Sequential()\n","ANN7.add(Dense(64, input_shape=(var,), activation='relu'))\n","#ANN7.add(Dropout(0.2))\n","ANN7.add(Dense(64, activation='relu'))\n","#ANN7.add(Dropout(0.2))\n","ANN7.add(Dense(64,activation='relu'))\n","ANN7.add(Dense(64,activation='relu'))\n","ANN7.add(Dense(64,activation='relu'))\n","ANN7.add(Dense(64,activation='relu'))\n","ANN7.add(Dense(1))\n","ANN7.compile(loss='mean_squared_error', optimizer='Adam', metrics = [tf.keras.metrics.MeanSquaredError()])\n","print(ANN7.summary())"]},{"cell_type":"markdown","source":["The models are now ready to be trained"],"metadata":{"id":"i_7-INqFeiPd"}},{"cell_type":"markdown","metadata":{"id":"i5QGKu5C8T8P"},"source":["## **Model Train**"]},{"cell_type":"markdown","source":["First, we define Earlystopping as a callback with patience set to 7. this means that training will stop when validation error does not reduce for 7 epochs. "],"metadata":{"id":"fjCNlEoMeoFl"}},{"cell_type":"code","source":["callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)"],"metadata":{"id":"YclPt2vUeuU-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["With a batch size set to 64, callback set to our defined callback, and validation data set to our defined validation data split, we train the models for upto 200 epochs. Training may stop long before that thanks to earlystopping calllback"],"metadata":{"id":"etM1mpVBfDuk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YsjPKAQFr3_w"},"outputs":[],"source":["history1 = ANN1.fit(trainX1, trainY1,  validation_data=[valX1, valY1],batch_size=64,callbacks=[callback],\n","          verbose=2, epochs=200)"]},{"cell_type":"markdown","source":["We repeat the same process for all the time leads"],"metadata":{"id":"7PRiYdnDfmQv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OZu5wf378UAJ"},"outputs":[],"source":["history3 = ANN3.fit(trainX3, trainY3,  validation_data=[valX3, valY3],batch_size=64,callbacks=[callback],\n","          verbose=2, epochs=200)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ID2QjKk8W3N"},"outputs":[],"source":["history5 = ANN5.fit(trainX5, trainY5,  validation_data=[valX5, valY5],batch_size=64,callbacks=[callback],\n","          verbose=2, epochs=200)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qYRlyt-H8bc1"},"outputs":[],"source":["history7 = ANN7.fit(trainX7, trainY7,  validation_data=[valX7, valY7],batch_size=64,callbacks=[callback],\n","          verbose=2, epochs=200)"]},{"cell_type":"markdown","source":["Training is complete."],"metadata":{"id":"6lw5s-GyfwEU"}},{"cell_type":"markdown","metadata":{"id":"874FOQer8ZO3"},"source":["## **Plots**"]},{"cell_type":"markdown","source":["These plots show the change of training loss and validation loss while training the model."],"metadata":{"id":"PfcAjPSGf2b1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Irjz4ENxF1g1"},"outputs":[],"source":["#plot the training and validation accuracy and loss at each epoch\n","train_loss1 = history1.history['loss']\n","val_loss1 = history1.history['val_loss']\n","epochs = range(1, len(train_loss1) + 1)\n","plt.plot(epochs, train_loss1, 'y', label='Training loss')\n","plt.plot(epochs, val_loss1, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKLuZUDMA040"},"outputs":[],"source":["train_loss3 = history3.history['loss']\n","val_loss3 = history3.history['val_loss']\n","epochs = range(1, len(train_loss3) + 1)\n","plt.plot(epochs, train_loss3, 'y', label='Training loss')\n","plt.plot(epochs, val_loss3, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7X6aCsKA15M"},"outputs":[],"source":["train_loss5 = history5.history['loss']\n","val_loss5 = history5.history['val_loss']\n","epochs = range(1, len(train_loss5) + 1)\n","plt.plot(epochs, train_loss5, 'y', label='Training loss')\n","plt.plot(epochs, val_loss5, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejfth3XeA6dE"},"outputs":[],"source":["train_loss7 = history7.history['loss']\n","val_loss7 = history7.history['val_loss']\n","epochs = range(1, len(train_loss7) + 1)\n","plt.plot(epochs, train_loss7, 'y', label='Training loss')\n","plt.plot(epochs, val_loss7, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Ny_foq8n8f5e"},"source":["## **prediction**"]},{"cell_type":"markdown","source":["It's time to make some predictions using our held out test dataset. we also use the train and validation dataset to calculate trianing and validation errors"],"metadata":{"id":"WMl_LjdLgMhN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pjI7QJ91takE"},"outputs":[],"source":["trainpredictANN1 = ANN1.predict(trainX1)\n","valpredictANN1 = ANN1.predict(valX1)\n","testpredictANN1 = ANN1.predict(testX1)\n","\n","trainpredictANN3 = ANN3.predict(trainX3)\n","valpredictANN3 = ANN3.predict(valX3)\n","testpredictANN3 = ANN3.predict(testX3)\n","\n","trainpredictANN5 = ANN5.predict(trainX5)\n","valpredictANN5 = ANN5.predict(valX5)\n","testpredictANN5 = ANN5.predict(testX5)\n","\n","trainpredictANN7 = ANN7.predict(trainX7)\n","valpredictANN7 = ANN7.predict(valX7)\n","testpredictANN7 = ANN7.predict(testX7)"]},{"cell_type":"markdown","metadata":{"id":"5yGBULR48mr2"},"source":["## **Evaluation**"]},{"cell_type":"markdown","source":["Now we calculate RMSE values for train, test and validation datasets"],"metadata":{"id":"gmYJ80e1nb9U"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YQs0O7ACwRBA"},"outputs":[],"source":["trainScoreANN1 = math.sqrt(mean_squared_error(trainY1, trainpredictANN1))\n","print('Train Score 1: %.2f RMSE' % (trainScoreANN1))\n","valScoreANN1 = math.sqrt(mean_squared_error(valY1, valpredictANN1))\n","print('val Score 1: %.2f RMSE' % (valScoreANN1))\n","testScoreANN1 = math.sqrt(mean_squared_error(testY1, testpredictANN1))\n","print('Test Score 1: %.2f RMSE' % (testScoreANN1))\n","\n","trainScoreANN3 = math.sqrt(mean_squared_error(trainY3, trainpredictANN3))\n","print('Train Score 3: %.2f RMSE' % (trainScoreANN3))\n","valScoreANN3 = math.sqrt(mean_squared_error(valY3, valpredictANN3))\n","print('val Score 3: %.2f RMSE' % (valScoreANN3))\n","testScoreANN3 = math.sqrt(mean_squared_error(testY3, testpredictANN3))\n","print('Test Score 3: %.2f RMSE' % (testScoreANN3))\n","\n","trainScoreANN5 = math.sqrt(mean_squared_error(trainY5, trainpredictANN5))\n","print('Train Score 5: %.2f RMSE' % (trainScoreANN5))\n","valScoreANN5 = math.sqrt(mean_squared_error(valY5, valpredictANN5))\n","print('val Score 5: %.2f RMSE' % (valScoreANN5))\n","testScoreANN5 = math.sqrt(mean_squared_error(testY5, testpredictANN5))\n","print('Test Score 5: %.2f RMSE' % (testScoreANN5))\n","\n","trainScoreANN7 = math.sqrt(mean_squared_error(trainY7, trainpredictANN7))\n","print('Train Score 7: %.2f RMSE' % (trainScoreANN7))\n","valScoreANN7 = math.sqrt(mean_squared_error(valY7, valpredictANN7))\n","print('val Score 7: %.2f RMSE' % (valScoreANN7))\n","testScoreANN7 = math.sqrt(mean_squared_error(testY7, testpredictANN7))\n","print('Test Score 7: %.2f RMSE' % (testScoreANN7))"]},{"cell_type":"markdown","source":["Now we calculate r2 values for train, test and validation datasets"],"metadata":{"id":"dZ9HhKyYn0ox"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMe9t2ecJ5m2"},"outputs":[],"source":["trainr2_ANN1 =r2_score(trainY1, trainpredictANN1)\n","print('Train Score 1: %.2f RMSE' % (trainr2_ANN1))\n","valr2_ANN1 =r2_score(valY1, valpredictANN1)\n","print('val Score 1: %.2f RMSE' % (valr2_ANN1))\n","testr2_ANN1 =r2_score(testY1, testpredictANN1)\n","print('Test Score 1: %.2f RMSE' % (testr2_ANN1))\n","\n","trainr2_ANN3 =r2_score(trainY3, trainpredictANN3)\n","print('Train Score 3: %.2f RMSE' % (trainr2_ANN3))\n","valr2_ANN3 =r2_score(valY3, valpredictANN3)\n","print('val Score 3: %.2f RMSE' % (valr2_ANN3))\n","testr2_ANN3 =r2_score(testY3, testpredictANN3)\n","print('Test Score 3: %.2f RMSE' % (testr2_ANN3))\n","\n","trainr2_ANN5 =r2_score(trainY5, trainpredictANN5)\n","print('Train Score 5: %.2f RMSE' % (trainr2_ANN5))\n","valr2_ANN5 =r2_score(valY5, valpredictANN5)\n","print('val Score 5: %.2f RMSE' % (valr2_ANN5))\n","testr2_ANN5 =r2_score(testY5, testpredictANN5)\n","print('Test Score 5: %.2f RMSE' % (testr2_ANN5))\n","\n","trainr2_ANN7 =r2_score(trainY7, trainpredictANN7)\n","print('Train Score 7: %.2f RMSE' % (trainr2_ANN7))\n","valr2_ANN7 =r2_score(valY7, valpredictANN7)\n","print('val Score 7: %.2f RMSE' % (valr2_ANN7))\n","testr2_ANN7 =r2_score(testY7, testpredictANN7)\n","print('Test Score 7: %.2f RMSE' % (testr2_ANN7))"]},{"cell_type":"markdown","source":["Now we create a dataframe named rmse_vals including the rmse values for the training, validation and test datasets for the ANN model"],"metadata":{"id":"_vI6_zUnoATT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"A3unaylBwxSB"},"outputs":[],"source":["rmse_vals={'ANN':[trainScoreANN1,valScoreANN1,testScoreANN1,trainScoreANN3,valScoreANN3,testScoreANN3,trainScoreANN5,valScoreANN5,testScoreANN5,trainScoreANN7,valScoreANN7,testScoreANN7]}\n","df_rmse=pd.DataFrame(rmse_vals)"]},{"cell_type":"markdown","source":["Now we create a dataframe named r2_vals including the r2 values for the training, validation and test datasets for the ANN model"],"metadata":{"id":"n2gXQur4oWHU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"caOOnCX9J40f"},"outputs":[],"source":["r2_vals={'ANN':[trainr2_ANN1,valr2_ANN1,testr2_ANN1,trainr2_ANN3,valr2_ANN3,testr2_ANN3,trainr2_ANN5,valr2_ANN5,testr2_ANN5,trainr2_ANN7,valr2_ANN7,testr2_ANN7]}\n","df_r2=pd.DataFrame(r2_vals)"]},{"cell_type":"markdown","metadata":{"id":"QxiRzEASSVdJ"},"source":["## **Save ANN Models**"]},{"cell_type":"markdown","source":["Time to save the models to path so that they can be used later."],"metadata":{"id":"GsBVoj9kobiD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XlenOKlVSVD0"},"outputs":[],"source":["import os.path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGHLte-nShN9"},"outputs":[],"source":["ANN1.save('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/ANN/ANN1.h5')\n","\n","ANN3.save('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/ANN/ANN3.h5')\n","\n","ANN5.save('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/ANN/ANN5.h5')\n","\n","ANN7.save('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/ANN/ANN7.h5')"]},{"cell_type":"markdown","metadata":{"id":"nH8X8uWkw9dG"},"source":["# **Random Forest**"]},{"cell_type":"markdown","metadata":{"id":"KohAAAiC_JO_"},"source":["## **Import Models**"]},{"cell_type":"markdown","source":["If the models have already been develpoed, We can just import the saved models and move on to prediction. If not, then we have to train the models"],"metadata":{"id":"tDg1MOGko-Ma"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6es7fC5M_Mx4"},"outputs":[],"source":["RF1= joblib.load('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/RF/RF1.h5')\n","\n","RF3= joblib.load('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/RF/RF3.h5')\n","\n","RF5= joblib.load('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/RF/RF5.h5')\n","\n","RF7= joblib.load('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/RF/RF7.h5')"]},{"cell_type":"markdown","metadata":{"id":"MCO7cvXrEYnb"},"source":["## **Model Build and train**"]},{"cell_type":"markdown","source":["While building the models, number of esimators were set to 50, bootstrap was set to TRUE, oob_Score was set to TRUE, max_depth was set to 11, n_jobs set to -1 that inidicates the use of all the CPUs in the system, random state was set to 42. The model was then trained for the train dataset. "],"metadata":{"id":"tc86A019pGpu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sp1Y67qDEYnd"},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor\n","\n","RF1 = RandomForestRegressor(n_estimators=50, bootstrap=True, oob_score=True, max_depth=11, n_jobs=-1, random_state=42, verbose=2)\n","RF1.fit(trainX1,trainY1)"]},{"cell_type":"markdown","source":["The same was repeated for the remaining lead times."],"metadata":{"id":"UQ0Ne8tQprSb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CzVOH6egEYne"},"outputs":[],"source":["RF3 = RandomForestRegressor(n_estimators=50, bootstrap=True, oob_score=True, max_depth=11, n_jobs=-1, random_state=42, verbose=2)\n","RF3.fit(trainX3,trainY3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJ2WzawtEYnf"},"outputs":[],"source":["RF5 = RandomForestRegressor(n_estimators=50, bootstrap=True, oob_score=True, max_depth=11, n_jobs=-1, random_state=42, verbose=2)\n","RF5.fit(trainX5,trainY5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nj9PEJ8rEYng"},"outputs":[],"source":["RF7 = RandomForestRegressor(n_estimators=50, bootstrap=True, oob_score=True, max_depth=11, n_jobs=-1, random_state=42, verbose=2)\n","RF7.fit(trainX7,trainY7)"]},{"cell_type":"markdown","metadata":{"id":"AMwvm-HH-kyw"},"source":["## **prediction**"]},{"cell_type":"markdown","source":["It's time to make some predictions using our held out test dataset. we also use the train and validation dataset to calculate trianing and validation errors"],"metadata":{"id":"FCgMb0BA5g0Y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGiUEseN4ihS"},"outputs":[],"source":["trainpredictRF1 = RF1.predict(trainX1)\n","valpredictRF1 = RF1.predict(valX1)\n","testpredictRF1 = RF1.predict(testX1)\n","\n","trainpredictRF3 = RF3.predict(trainX3)\n","valpredictRF3 = RF3.predict(valX3)\n","testpredictRF3 = RF3.predict(testX3)\n","\n","trainpredictRF5 = RF5.predict(trainX5)\n","valpredictRF5 = RF5.predict(valX5)\n","testpredictRF5 = RF5.predict(testX5)\n","\n","trainpredictRF7 = RF7.predict(trainX7)\n","valpredictRF7 = RF7.predict(valX7)\n","testpredictRF7 = RF7.predict(testX7)"]},{"cell_type":"markdown","metadata":{"id":"zrKFVWD_-2gC"},"source":["## **Evaluation**"]},{"cell_type":"markdown","source":["Now we calculate RMSE values for train, test and validation datasets"],"metadata":{"id":"LGkMQb6v5m1G"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1652621329261,"user":{"displayName":"Alvee Hannan","userId":"12340570370596767258"},"user_tz":-360},"id":"fGZvJrajEot_","outputId":"8a6404df-302c-404f-8ceb-3e604a3f39d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Score 1: 0.13 RMSE\n","val Score 1: 0.29 RMSE\n","Test Score 1: 0.37 RMSE\n","Train Score 3: 0.28 RMSE\n","val Score 3: 0.61 RMSE\n","Test Score 3: 0.75 RMSE\n","Train Score 5: 0.42 RMSE\n","val Score 5: 0.85 RMSE\n","Test Score 5: 1.02 RMSE\n","Train Score 7: 0.55 RMSE\n","val Score 7: 1.10 RMSE\n","Test Score 7: 1.28 RMSE\n"]}],"source":["trainScoreRF1 = math.sqrt(mean_squared_error(trainY1, trainpredictRF1))\n","print('Train Score 1: %.2f RMSE' % (trainScoreRF1))\n","valScoreRF1 = math.sqrt(mean_squared_error(valY1, valpredictRF1))\n","print('val Score 1: %.2f RMSE' % (valScoreRF1))\n","testScoreRF1 = math.sqrt(mean_squared_error(testY1, testpredictRF1))\n","print('Test Score 1: %.2f RMSE' % (testScoreRF1))\n","\n","trainScoreRF3 = math.sqrt(mean_squared_error(trainY3, trainpredictRF3))\n","print('Train Score 3: %.2f RMSE' % (trainScoreRF3))\n","valScoreRF3 = math.sqrt(mean_squared_error(valY3, valpredictRF3))\n","print('val Score 3: %.2f RMSE' % (valScoreRF3))\n","testScoreRF3 = math.sqrt(mean_squared_error(testY3, testpredictRF3))\n","print('Test Score 3: %.2f RMSE' % (testScoreRF3))\n","\n","trainScoreRF5 = math.sqrt(mean_squared_error(trainY5, trainpredictRF5))\n","print('Train Score 5: %.2f RMSE' % (trainScoreRF5))\n","valScoreRF5 = math.sqrt(mean_squared_error(valY5, valpredictRF5))\n","print('val Score 5: %.2f RMSE' % (valScoreRF5))\n","testScoreRF5 = math.sqrt(mean_squared_error(testY5, testpredictRF5))\n","print('Test Score 5: %.2f RMSE' % (testScoreRF5))\n","\n","trainScoreRF7 = math.sqrt(mean_squared_error(trainY7, trainpredictRF7))\n","print('Train Score 7: %.2f RMSE' % (trainScoreRF7))\n","valScoreRF7 = math.sqrt(mean_squared_error(valY7, valpredictRF7))\n","print('val Score 7: %.2f RMSE' % (valScoreRF7))\n","testScoreRF7 = math.sqrt(mean_squared_error(testY7, testpredictRF7))\n","print('Test Score 7: %.2f RMSE' % (testScoreRF7))"]},{"cell_type":"markdown","source":["Now we calculate r2 values for train, test and validation datasets"],"metadata":{"id":"5uNvbw245o04"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1652621329262,"user":{"displayName":"Alvee Hannan","userId":"12340570370596767258"},"user_tz":-360},"id":"tIHIf8FaDDtF","outputId":"77840c26-05bb-4edf-ab3d-6921ebd99ce2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Score 1: 1.00 RMSE\n","val Score 1: 0.99 RMSE\n","Test Score 1: 0.99 RMSE\n","Train Score 3: 0.99 RMSE\n","val Score 3: 0.97 RMSE\n","Test Score 3: 0.95 RMSE\n","Train Score 5: 0.99 RMSE\n","val Score 5: 0.94 RMSE\n","Test Score 5: 0.91 RMSE\n","Train Score 7: 0.98 RMSE\n","val Score 7: 0.90 RMSE\n","Test Score 7: 0.86 RMSE\n"]}],"source":["trainr2_RF1 =r2_score(trainY1, trainpredictRF1)\n","print('Train Score 1: %.2f RMSE' % (trainr2_RF1))\n","valr2_RF1 =r2_score(valY1, valpredictRF1)\n","print('val Score 1: %.2f RMSE' % (valr2_RF1))\n","testr2_RF1 =r2_score(testY1, testpredictRF1)\n","print('Test Score 1: %.2f RMSE' % (testr2_RF1))\n","\n","trainr2_RF3 =r2_score(trainY3, trainpredictRF3)\n","print('Train Score 3: %.2f RMSE' % (trainr2_RF3))\n","valr2_RF3 =r2_score(valY3, valpredictRF3)\n","print('val Score 3: %.2f RMSE' % (valr2_RF3))\n","testr2_RF3 =r2_score(testY3, testpredictRF3)\n","print('Test Score 3: %.2f RMSE' % (testr2_RF3))\n","\n","trainr2_RF5 =r2_score(trainY5, trainpredictRF5)\n","print('Train Score 5: %.2f RMSE' % (trainr2_RF5))\n","valr2_RF5 =r2_score(valY5, valpredictRF5)\n","print('val Score 5: %.2f RMSE' % (valr2_RF5))\n","testr2_RF5 =r2_score(testY5, testpredictRF5)\n","print('Test Score 5: %.2f RMSE' % (testr2_RF5))\n","\n","trainr2_RF7 =r2_score(trainY7, trainpredictRF7)\n","print('Train Score 7: %.2f RMSE' % (trainr2_RF7))\n","valr2_RF7 =r2_score(valY7, valpredictRF7)\n","print('val Score 7: %.2f RMSE' % (valr2_RF7))\n","testr2_RF7 =r2_score(testY7, testpredictRF7)\n","print('Test Score 7: %.2f RMSE' % (testr2_RF7))"]},{"cell_type":"markdown","source":["Now we edit the dataframe named df_rmse that contained the rmse values for the DNN model by adding the rmse scores for the RF model"],"metadata":{"id":"qGSzpu395rb-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"et_h4CeTLnTs"},"outputs":[],"source":["rmse_RFvals={'RF':[trainScoreRF1,valScoreRF1,testScoreRF1,trainScoreRF3,valScoreRF3,testScoreRF3,trainScoreRF5,valScoreRF5,testScoreRF5,trainScoreRF7,valScoreRF7,testScoreRF7]}\n","df_rmse_RF=pd.DataFrame(rmse_RFvals)\n","df_rmse=df_rmse.join(df_rmse_RF)\n","\n"]},{"cell_type":"markdown","source":["we do  the same for r2 values"],"metadata":{"id":"7h50BMjS58uW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1KvXlOWbpYG"},"outputs":[],"source":["r2_RFvals={'RF':[trainr2_RF1,valr2_RF1,testr2_RF1,trainr2_RF3,valr2_RF3,testr2_RF3,trainr2_RF5,valr2_RF5,testr2_RF5,trainr2_RF7,valr2_RF7,testr2_RF7]}\n","df_r2_RF=pd.DataFrame(r2_RFvals)\n","df_r2=df_r2.join(df_r2_RF)"]},{"cell_type":"markdown","metadata":{"id":"vnAVrAnrXD8-"},"source":["## **Save RF Models**"]},{"cell_type":"markdown","source":["Time to save the models so they can be used later."],"metadata":{"id":"aeXRWOhz5_-N"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mvc-rj49YNAb"},"outputs":[],"source":["import joblib"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1118,"status":"ok","timestamp":1652161207162,"user":{"displayName":"Alvee Hannan","userId":"12340570370596767258"},"user_tz":-360},"id":"_wpdeYAYXI4O","outputId":"1af536fb-968f-4413-a1a9-e2f10d915701"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/Thesis/SavedModels/TpSwvl/RF/RF7.h5']"]},"metadata":{},"execution_count":46}],"source":["joblib.dump(RF1,\"/content/drive/MyDrive/Thesis/SavedModels/\"+vars+\"/RF/RF1.h5\")\n","\n","joblib.dump(RF3,\"/content/drive/MyDrive/Thesis/SavedModels/\"+vars+\"/RF/RF3.h5\")\n","\n","joblib.dump(RF5,\"/content/drive/MyDrive/Thesis/SavedModels/\"+vars+\"/RF/RF5.h5\")\n","\n","joblib.dump(RF7,\"/content/drive/MyDrive/Thesis/SavedModels/\"+vars+\"/RF/RF7.h5\")"]},{"cell_type":"markdown","metadata":{"id":"c5KFehzTkHRA"},"source":["# **CatboostRegressor**"]},{"cell_type":"markdown","metadata":{"id":"bFyjzLk6bfwx"},"source":["## **Install CatBoostregressor**"]},{"cell_type":"markdown","source":["First, We must install Catboost regresssor using pip"],"metadata":{"id":"MU2yMlDZ6U_7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzEM97p9kFtg"},"outputs":[],"source":["pip install catboost"]},{"cell_type":"markdown","source":["Now we load our required libraries"],"metadata":{"id":"6sZxV-to6ft2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7g22G5htkxTF"},"outputs":[],"source":["from catboost import Pool,CatBoostRegressor"]},{"cell_type":"markdown","metadata":{"id":"ennBukAQ_6kl"},"source":["## **Load models**"]},{"cell_type":"markdown","source":["Now we load the previoiusly saved models for making predictions. If we need to train the models, this section is to be ignored"],"metadata":{"id":"Mzt3yDy47sWt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"R2CzjWRy__R_"},"outputs":[],"source":["CB1= joblib.load('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/CB/CB1.h5')\n","\n","CB3= joblib.load('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/CB/CB3.h5')\n","\n","CB5= joblib.load('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/CB/CB5.h5')\n","\n","CB7= joblib.load('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/CB/CB7.h5')"]},{"cell_type":"markdown","metadata":{"id":"2X8-0CAcbrhC"},"source":["## **Build Models and Run**"]},{"cell_type":"markdown","source":["to train the models, first we make a pool of data for the train and validation sets separately. then we build the model setting iterations to 8000, but keeping overfitting detector on. What this does is that it stops training of the models when the validation losses dont decrease for certain number of steps ( in our case 5 iterations) learning rate is set to 0.002, depth set to 10, loss function set to RMSE, and random seed set to 42. Finally the model was trained for the training dataset while setting the validation dataset for overfitting detection."],"metadata":{"id":"_PKOEU0K8E70"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8mOeBS1rf5j"},"outputs":[],"source":["CB1train = Pool(data=trainX1,\n","                label=trainY1)\n","CB1val = Pool(data=testX1,\n","              label=testY1)\n","\n","CB1 = CatBoostRegressor(iterations=8000,\n","                        learning_rate=0.002,\n","                        depth=10,\n","                        l2_leaf_reg=20,\n","                        model_size_reg=None,\n","                        loss_function='RMSE',\n","                        od_wait=5,\n","                        od_type=\"Iter\",\n","                        random_seed = 42)\n","\n","CB1.fit(CB1train,\n","        use_best_model = True,\n","        eval_set = CB1val,\n","        )"]},{"cell_type":"markdown","source":["The same was repeated for all lead times."],"metadata":{"id":"cKn26agp-HNV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WI8DXYFtBfXW"},"outputs":[],"source":["CB3train = Pool(data=trainX3,\n","                label=trainY3)\n","CB3val = Pool(data=testX3,\n","              label=testY3)\n","\n","CB3 = CatBoostRegressor(iterations=8000,\n","                        learning_rate=0.002,\n","                        depth=10,\n","                        l2_leaf_reg=20,\n","                        model_size_reg=None,\n","                        loss_function='RMSE',\n","                        od_wait=5,\n","                        od_type=\"Iter\",\n","                        random_seed = 42)\n","\n","CB3.fit(CB3train,\n","        use_best_model = True,\n","        eval_set = CB3val,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EmAAueL8Blrj"},"outputs":[],"source":["CB5train = Pool(data=trainX5,\n","                label=trainY5)\n","CB5val = Pool(data=testX5,\n","              label=testY5)\n","\n","CB5 = CatBoostRegressor(iterations=8000,\n","                        learning_rate=0.002,\n","                        depth=10,\n","                        l2_leaf_reg=20,\n","                        model_size_reg=None,\n","                        loss_function='RMSE',\n","                        od_wait=5,\n","                        od_type=\"Iter\",\n","                        random_seed = 42)\n","\n","CB5.fit(CB1train,\n","        use_best_model = True,\n","        eval_set = CB5val,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8B_8jCB9EE3z"},"outputs":[],"source":["CB7train = Pool(data=trainX7,\n","                label=trainY7)\n","CB7val = Pool(data=testX7,\n","              label=testY7)\n","\n","CB7 = CatBoostRegressor(iterations=5000,\n","                        learning_rate=0.002,\n","                        depth=10,\n","                        l2_leaf_reg=20,\n","                        model_size_reg=None,\n","                        loss_function='RMSE',\n","                        od_wait=5,\n","                        od_type=\"Iter\",\n","                        random_seed = 42)\n","\n","CB7.fit(CB7train,\n","        use_best_model = True,\n","        eval_set = CB7val,\n","        )"]},{"cell_type":"markdown","metadata":{"id":"UK1aOSw-b6Tp"},"source":["## **Make predictions**"]},{"cell_type":"markdown","source":["It's time to make some predictions using our held out test dataset. we also use the train and validation dataset to calculate trianing and validation errors"],"metadata":{"id":"fhkJrHO_-TXX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Cc-VZagsuE4"},"outputs":[],"source":["trainpredictCB1 = CB1.predict(trainX1)\n","valpredictCB1 = CB1.predict(valX1)\n","testpredictCB1 = CB1.predict(testX1)\n","\n","trainpredictCB3 = CB3.predict(trainX3)\n","valpredictCB3 = CB3.predict(valX3)\n","testpredictCB3 = CB3.predict(testX3)\n","\n","trainpredictCB5 = CB5.predict(trainX5)\n","valpredictCB5 = CB5.predict(valX5)\n","testpredictCB5 = CB5.predict(testX5)\n","\n","trainpredictCB7 = CB7.predict(trainX7)\n","valpredictCB7 = CB7.predict(valX7)\n","testpredictCB7 = CB7.predict(testX7)"]},{"cell_type":"markdown","metadata":{"id":"1uFfbmXUcA1F"},"source":["## **Evaluate model**"]},{"cell_type":"markdown","source":["Now we calculate RMSE values for train, test and validation datasets"],"metadata":{"id":"cSyakF1H-Zzn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KO-Z77JBs5dO"},"outputs":[],"source":["trainScoreCB1 = math.sqrt(mean_squared_error(trainY1, trainpredictCB1))\n","print('Train Score 1: %.2f RMSE' % (trainScoreCB1))\n","valScoreCB1 = math.sqrt(mean_squared_error(valY1, valpredictCB1))\n","print('val Score 1: %.2f RMSE' % (valScoreCB1))\n","testScoreCB1 = math.sqrt(mean_squared_error(testY1, testpredictCB1))\n","print('Test Score 1: %.2f RMSE' % (testScoreCB1))\n","\n","trainScoreCB3 = math.sqrt(mean_squared_error(trainY3, trainpredictCB3))\n","print('Train Score 3: %.2f RMSE' % (trainScoreCB3))\n","valScoreCB3 = math.sqrt(mean_squared_error(valY3, valpredictCB3))\n","print('val Score 3: %.2f RMSE' % (valScoreCB3))\n","testScoreCB3 = math.sqrt(mean_squared_error(testY3, testpredictCB3))\n","print('Test Score 3: %.2f RMSE' % (testScoreCB3))\n","\n","trainScoreCB5 = math.sqrt(mean_squared_error(trainY5, trainpredictCB5))\n","print('Train Score 5: %.2f RMSE' % (trainScoreCB5))\n","valScoreCB5 = math.sqrt(mean_squared_error(valY5, valpredictCB5))\n","print('val Score 5: %.2f RMSE' % (valScoreCB5))\n","testScoreCB5 = math.sqrt(mean_squared_error(testY5, testpredictCB5))\n","print('Test Score 5: %.2f RMSE' % (testScoreCB5))\n","\n","trainScoreCB7 = math.sqrt(mean_squared_error(trainY7, trainpredictCB7))\n","print('Train Score 7: %.2f RMSE' % (trainScoreCB7))\n","valScoreCB7 = math.sqrt(mean_squared_error(valY7, valpredictCB7))\n","print('val Score 7: %.2f RMSE' % (valScoreCB7))\n","testScoreCB7 = math.sqrt(mean_squared_error(testY7, testpredictCB7))\n","print('Test Score 7: %.2f RMSE' % (testScoreCB7))"]},{"cell_type":"markdown","source":["Now we calculate r2 values for train, test and validation datasets"],"metadata":{"id":"SXFvB3_e-bg1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GIILJlHKCKEA"},"outputs":[],"source":["trainr2_CB1 =r2_score(trainY1, trainpredictCB1)\n","print('Train Score 1: %.2f RMSE' % (trainr2_CB1))\n","valr2_CB1 =r2_score(valY1, valpredictCB1)\n","print('val Score 1: %.2f RMSE' % (valr2_CB1))\n","testr2_CB1 =r2_score(testY1, testpredictCB1)\n","print('Test Score 1: %.2f RMSE' % (testr2_CB1))\n","\n","trainr2_CB3 =r2_score(trainY3, trainpredictCB3)\n","print('Train Score 3: %.2f RMSE' % (trainr2_CB3))\n","valr2_CB3 =r2_score(valY3, valpredictCB3)\n","print('val Score 3: %.2f RMSE' % (valr2_CB3))\n","testr2_CB3 =r2_score(testY3, testpredictCB3)\n","print('Test Score 3: %.2f RMSE' % (testr2_CB3))\n","\n","trainr2_CB5 =r2_score(trainY5, trainpredictCB5)\n","print('Train Score 5: %.2f RMSE' % (trainr2_CB5))\n","valr2_CB5 =r2_score(valY5, valpredictCB5)\n","print('val Score 5: %.2f RMSE' % (valr2_CB5))\n","testr2_CB5 =r2_score(testY5, testpredictCB5)\n","print('Test Score 5: %.2f RMSE' % (testr2_CB5))\n","\n","trainr2_CB7 =r2_score(trainY7, trainpredictCB7)\n","print('Train Score 7: %.2f RMSE' % (trainr2_CB7))\n","valr2_CB7 =r2_score(valY7, valpredictCB7)\n","print('val Score 7: %.2f RMSE' % (valr2_CB7))\n","testr2_CB7 =r2_score(testY7, testpredictCB7)\n","print('Test Score 7: %.2f RMSE' % (testr2_CB7))"]},{"cell_type":"markdown","metadata":{"id":"aiIAMF7g0wOK"},"source":["## **Edit Error df**"]},{"cell_type":"markdown","source":["The dataframe containing rmse values are now updated for the new model also"],"metadata":{"id":"kEaPTFEZ-gZm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjKhMCaUCJn5"},"outputs":[],"source":["rmse_CBvals={'CB':[trainScoreCB1,valScoreCB1,testScoreCB1,trainScoreCB3,valScoreCB3,testScoreCB3,trainScoreCB5,valScoreCB5,testScoreCB5,trainScoreCB7,valScoreCB7,testScoreCB7]}\n","df_rmse_CB=pd.DataFrame(rmse_CBvals)\n","df_rmse=df_rmse.join(df_rmse_CB)\n","\n"]},{"cell_type":"markdown","source":["the same is done for the dataframe containing r2 values"],"metadata":{"id":"7Fxpl1Ky-sqA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5F-p-3TWuwJ"},"outputs":[],"source":["r2_CBvals={'CB':[trainr2_CB1,valr2_CB1,testr2_CB1,trainr2_CB3,valr2_CB3,testr2_CB3,trainr2_CB5,valr2_CB5,testr2_CB5,trainr2_CB7,valr2_CB7,testr2_CB7]}\n","df_r2_CB=pd.DataFrame(r2_CBvals)\n","df_r2=df_r2.join(df_r2_CB)"]},{"cell_type":"markdown","source":["## **Show CB tree**"],"metadata":{"id":"0We7-Terzkzk"}},{"cell_type":"markdown","source":["this code can help us visualise a tree layer "],"metadata":{"id":"bnbeURtn-6Ea"}},{"cell_type":"code","source":["CB1.plot_tree(tree_idx=0,)"],"metadata":{"id":"d2LRlfehzjuq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lmAa6qzXY80M"},"source":["## **Save CB models**"]},{"cell_type":"markdown","source":["Time to save the models for future use"],"metadata":{"id":"tAYPYAPu_B_H"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1384,"status":"ok","timestamp":1652162478220,"user":{"displayName":"Alvee Hannan","userId":"12340570370596767258"},"user_tz":-360},"id":"1sh_5zW5ZBst","outputId":"e5649d62-f109-4904-f0c6-fd76f8f7c191"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/Thesis/SavedModels/Tp/CB/CB7.h5']"]},"metadata":{},"execution_count":63}],"source":["joblib.dump(CB1,\"/content/drive/MyDrive/Thesis/SavedModels/\"+vars+\"/CB/CB1.h5\")\n","\n","joblib.dump(CB3,\"/content/drive/MyDrive/Thesis/SavedModels/\"+vars+\"/CB/CB3.h5\")\n","\n","joblib.dump(CB5,\"/content/drive/MyDrive/Thesis/SavedModels/\"+vars+\"/CB/CB5.h5\")\n","\n","joblib.dump(CB7,\"/content/drive/MyDrive/Thesis/SavedModels/\"+vars+\"/CB/CB7.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQVJnUM0ux0t"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"sMKdQjbVbEfd"},"source":["# **LSTM**"]},{"cell_type":"markdown","source":["If the models have already been develpoed, We can just import the saved models and move on to prediction. If not, then we have to train the models"],"metadata":{"id":"lLqT0e_J_W_t"}},{"cell_type":"markdown","metadata":{"id":"ZGlNu-oXXWM-"},"source":["## **Data Processing LSTM**"]},{"cell_type":"markdown","source":["Processing data for the LSTM model is a little bit different than the other models.  First few steps, however, are similar"],"metadata":{"id":"9PXornFM_aoG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6MqcE4Jdw_H"},"outputs":[],"source":["dataframe"]},{"cell_type":"markdown","source":["dfX and dfY are defined as the parent sets for input and target"],"metadata":{"id":"_zq0HCHHCSNL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_z36jGTjgOMY"},"outputs":[],"source":["df = dataframe.set_index('Date')\n","dfX = df[list(df)[0:var]]\n","dfY=df[['WL']]"]},{"cell_type":"markdown","source":["The data are now split into train, validation and test datasets"],"metadata":{"id":"cjOg_ZPaFvQp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZLTiKpr0K3V"},"outputs":[],"source":["train_size = int(len(dfX) * 0.5)\n","val_size = int(len(dfX) * 0.2)\n","test_size = len(dfX) - train_size - val_size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-n8E3ek1YJh"},"outputs":[],"source":["Xtrain = dfX[:train_size]\n","print(Xtrain.shape)\n","Ytrain = dfY[:train_size]\n","print(Ytrain.shape)\n","\n","Xval = dfX[train_size:-test_size]\n","print(Xval.shape)\n","Yval = dfY[train_size:-test_size]\n","print(Yval.shape)\n","\n","Xtest = dfX[-test_size:]\n","print(Xtest.shape)\n","Ytest = dfY[-test_size:]\n","print(Ytest.shape)"]},{"cell_type":"markdown","source":["Empty lists are created to be populated using formatted training data"],"metadata":{"id":"4QOfo_ViF-IU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"A3rS0_yphQsI"},"outputs":[],"source":["#Empty lists to be populated using formatted training data\n","trainX_LSTM1 = []\n","valX_LSTM1 = []\n","trainY_LSTM1 = []\n","testX_LSTM1 = []\n","valY_LSTM1 = []\n","testY_LSTM1 = []\n","\n","trainX_LSTM3 = []\n","valX_LSTM3 = []\n","trainY_LSTM3 = []\n","testX_LSTM3 = []\n","valY_LSTM3 =[]\n","testY_LSTM3 = []\n","\n","trainX_LSTM5 = []\n","trainY_LSTM5 = []\n","valX_LSTM5 = []\n","valY_LSTM5 = []\n","testX_LSTM5 = []\n","testY_LSTM5 = []\n","\n","trainX_LSTM7 = []\n","trainY_LSTM7 = []\n","valX_LSTM7 = []\n","valY_LSTM7 = []\n","testX_LSTM7 = []\n","testY_LSTM7 = []"]},{"cell_type":"markdown","source":["As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features.\n","\n","n_future indicate Number of days we want to look into the future based on the past days.\n","\n","n_past indicate Number of past days we want to use to predict the future."],"metadata":{"id":"jTphn7x2GDIV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VCgEkm3AhzFV"},"outputs":[],"source":["#As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features.\n","n_future1=1\n","n_future3=3\n","n_future5=5\n","n_future7=7   # Number of days we want to look into the future based on the past days.\n","\n","\n","n_past = 14  # Number of past days we want to use to predict the future."]},{"cell_type":"markdown","source":["Now we Reformat input data into a shape: (n_samples x timesteps x n_features) and convert them to numpy array"],"metadata":{"id":"MW_cgjD-GZDN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2j883T3UPu4q"},"outputs":[],"source":["#Reformat input data into a shape: (n_samples x timesteps x n_features)\n","\n","for i1 in range(n_past, len(Xtrain) - n_future1 +1):\n","    trainX_LSTM1.append(Xtrain.iloc[i1 - n_past:i1, 0:Xtrain.shape[1]])\n","    trainY_LSTM1.append(Ytrain.iloc[i1 + n_future1 - 1])\n","for k1 in range(n_past, len(Xval) - n_future1 +1):\n","    valX_LSTM1.append(Xval.iloc[k1 - n_past:k1, 0:Xval.shape[1]])\n","    valY_LSTM1.append(Yval.iloc[k1 + n_future1 - 1])   \n","for j1 in range(n_past, len(Xtest) - n_future1 +1):\n","    testX_LSTM1.append(Xtest.iloc[j1 - n_past:j1, 0:Xtest.shape[1]])\n","    testY_LSTM1.append(Ytest.iloc[j1 + n_future1 - 1])\n","\n","trainX_LSTM1, trainY_LSTM1 = np.array(trainX_LSTM1), np.array(trainY_LSTM1)\n","valX_LSTM1, valY_LSTM1 = np.array(valX_LSTM1), np.array(valY_LSTM1)\n","testX_LSTM1, testY_LSTM1 = np.array(testX_LSTM1), np.array(testY_LSTM1)\n","\n","\n","for i3 in range(n_past, len(Xtrain) - n_future3 +1):\n","    trainX_LSTM3.append(Xtrain.iloc[i3 - n_past:i3, 0:Xtrain.shape[1]])\n","    trainY_LSTM3.append(Ytrain.iloc[i3 + n_future3 - 1])\n","for k3 in range(n_past, len(Xval) - n_future3 +1):\n","    valX_LSTM3.append(Xval.iloc[k3 - n_past:k3, 0:Xval.shape[1]])\n","    valY_LSTM3.append(Yval.iloc[k3 + n_future3 - 1])   \n","for j3 in range(n_past, len(Xtest) - n_future3 +1):\n","    testX_LSTM3.append(Xtest.iloc[j3 - n_past:j3, 0:Xtest.shape[1]])\n","    testY_LSTM3.append(Ytest.iloc[j3 + n_future3 - 1])\n","\n","trainX_LSTM3, trainY_LSTM3 = np.array(trainX_LSTM3), np.array(trainY_LSTM3)\n","valX_LSTM3, valY_LSTM3 = np.array(valX_LSTM3), np.array(valY_LSTM3)\n","testX_LSTM3, testY_LSTM3 = np.array(testX_LSTM3), np.array(testY_LSTM3)\n","\n","for i5 in range(n_past, len(Xtrain) - n_future5 +1):\n","    trainX_LSTM5.append(Xtrain.iloc[i5 - n_past:i5, 0:Xtrain.shape[1]])\n","    trainY_LSTM5.append(Ytrain.iloc[i5 + n_future5 - 1])\n","for k5 in range(n_past, len(Xval) - n_future5 +1):\n","    valX_LSTM5.append(Xval.iloc[k5 - n_past:k5, 0:Xval.shape[1]])\n","    valY_LSTM5.append(Yval.iloc[k5 + n_future5 - 1])   \n","for j5 in range(n_past, len(Xtest) - n_future5 +1):\n","    testX_LSTM5.append(Xtest.iloc[j5 - n_past:j5, 0:Xtest.shape[1]])\n","    testY_LSTM5.append(Ytest.iloc[j5 + n_future5 - 1])\n","\n","trainX_LSTM5, trainY_LSTM5 = np.array(trainX_LSTM5), np.array(trainY_LSTM5)\n","valX_LSTM5, valY_LSTM5 = np.array(valX_LSTM5), np.array(valY_LSTM5)\n","testX_LSTM5, testY_LSTM5 = np.array(testX_LSTM5), np.array(testY_LSTM5)\n","\n","for i7 in range(n_past, len(Xtrain) - n_future7 +1):\n","    trainX_LSTM7.append(Xtrain.iloc[i7 - n_past:i7, 0:Xtrain.shape[1]])\n","    trainY_LSTM7.append(Ytrain.iloc[i7 + n_future7 - 1])\n","for k7 in range(n_past, len(Xval) - n_future7 +1):\n","    valX_LSTM7.append(Xval.iloc[k7 - n_past:k7, 0:Xval.shape[1]])\n","    valY_LSTM7.append(Yval.iloc[k7 + n_future7 - 1])   \n","for j7 in range(n_past, len(Xtest) - n_future7 +1):\n","    testX_LSTM7.append(Xtest.iloc[j7 - n_past:j7, 0:Xtest.shape[1]])\n","    testY_LSTM7.append(Ytest.iloc[j7 + n_future7 - 1])\n","\n","trainX_LSTM7, trainY_LSTM7 = np.array(trainX_LSTM7), np.array(trainY_LSTM7)\n","valX_LSTM7, valY_LSTM7 = np.array(valX_LSTM7), np.array(valY_LSTM7)\n","testX_LSTM7, testY_LSTM7 = np.array(testX_LSTM7), np.array(testY_LSTM7)\n"]},{"cell_type":"markdown","source":["We check the input shapes "],"metadata":{"id":"Vmnisrp2GeFn"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1652621412543,"user":{"displayName":"Alvee Hannan","userId":"12340570370596767258"},"user_tz":-360},"id":"ZHEGgk22h1Im","outputId":"6553e5a9-1ac9-46d4-e008-224b7a1f10c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["trainX_LSTM1 shape == (2543, 14, 2).\n","trainY_LSTM1 shape == (2543, 1).\n","testX_LSTM1 shape == (1521, 14, 2).\n","testY_LSTM1 shape == (1521, 1).\n","trainX_LSTM3 shape == (2541, 14, 2).\n","trainY_LSTM3 shape == (2541, 1).\n","testX_LSTM3 shape == (1519, 14, 2).\n","testY_LSTM3 shape == (1519, 1).\n","trainX_LSTM5 shape == (2539, 14, 2).\n","trainY_LSTM5 shape == (2539, 1).\n","testX_LSTM5 shape == (1517, 14, 2).\n","testY_LSTM5 shape == (1517, 1).\n","trainX_LSTM7 shape == (2537, 14, 2).\n","trainY_LSTM7 shape == (2537, 1).\n","testX_LSTM7 shape == (1515, 14, 2).\n","testY_LSTM7 shape == (1515, 1).\n"]}],"source":["print('trainX_LSTM1 shape == {}.'.format(trainX_LSTM1.shape))\n","print('trainY_LSTM1 shape == {}.'.format(trainY_LSTM1.shape))\n","print('testX_LSTM1 shape == {}.'.format(testX_LSTM1.shape))\n","print('testY_LSTM1 shape == {}.'.format(testY_LSTM1.shape))\n","\n","print('trainX_LSTM3 shape == {}.'.format(trainX_LSTM3.shape))\n","print('trainY_LSTM3 shape == {}.'.format(trainY_LSTM3.shape))\n","print('testX_LSTM3 shape == {}.'.format(testX_LSTM3.shape))\n","print('testY_LSTM3 shape == {}.'.format(testY_LSTM3.shape))\n","\n","print('trainX_LSTM5 shape == {}.'.format(trainX_LSTM5.shape))\n","print('trainY_LSTM5 shape == {}.'.format(trainY_LSTM5.shape))\n","print('testX_LSTM5 shape == {}.'.format(testX_LSTM5.shape))\n","print('testY_LSTM5 shape == {}.'.format(testY_LSTM5.shape))\n","\n","print('trainX_LSTM7 shape == {}.'.format(trainX_LSTM7.shape))\n","print('trainY_LSTM7 shape == {}.'.format(trainY_LSTM7.shape))\n","print('testX_LSTM7 shape == {}.'.format(testX_LSTM7.shape))\n","print('testY_LSTM7 shape == {}.'.format(testY_LSTM7.shape))"]},{"cell_type":"markdown","metadata":{"id":"kamix-qZAKga"},"source":["## **Load Models**"]},{"cell_type":"markdown","source":["We load earlier saved models from path. if not, then we proceeed to build models"],"metadata":{"id":"rBk6M26JGxq9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ul9nv2AuARKL"},"outputs":[],"source":["LSTM1=load_model('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/LSTM/LSTM1.h5')\n","\n","LSTM3=load_model('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/LSTM/LSTM3.h5')\n","\n","LSTM5=load_model('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/LSTM/LSTM5.h5')\n","\n","LSTM7=load_model('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/LSTM/LSTM7.h5')"]},{"cell_type":"markdown","metadata":{"id":"sLMqAK3tRtXm"},"source":["## **Building LSTM Models**"]},{"cell_type":"markdown","source":["For building the DNN models, we define the model as sequential. then we add 3 LSTM layers with 64 neurons each, with activation function set to ReLU. the first layer contains the input variables and has the shape as the variables. The last dense layer was set with a single output. for the last LSTM model, Return sequences was set to False\n","\n","finally, the models were compiled with loss function set to rmse and optimizer set to adam."],"metadata":{"id":"sHUsKYrwJiGh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxjRRpzmkLXO"},"outputs":[],"source":["# define the Autoencoder model\n","\n","LSTM1 = Sequential()\n","LSTM1.add(LSTM(64, activation='relu', input_shape=(trainX_LSTM1.shape[1], trainX_LSTM1.shape[2]), return_sequences=True))\n","#LSTM1.add(Dropout(0.2))\n","#LSTM1.add(LSTM(64, activation='relu', return_sequences=True))\n","LSTM1.add(LSTM(64, activation='relu', return_sequences=True))\n","LSTM1.add(LSTM(64, activation='relu', return_sequences=False))\n","LSTM1.add(Dense(1))\n","\n","LSTM1.compile(loss='mse', optimizer='Adam')\n","LSTM1.summary()"]},{"cell_type":"markdown","source":["The same was repeated for all the time leads"],"metadata":{"id":"0UJKlfn0J3u6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oOJqhoEbRT9w"},"outputs":[],"source":["LSTM3 = Sequential()\n","LSTM3.add(LSTM(64, activation='relu', input_shape=(trainX_LSTM3.shape[1], trainX_LSTM3.shape[2]), return_sequences=True))\n","#LSTM3.add(Dropout(0.2))\n","#LSTM3.add(LSTM(64, activation='relu', return_sequences=True))\n","LSTM3.add(LSTM(64, activation='relu', return_sequences=True))\n","LSTM3.add(LSTM(64, activation='relu', return_sequences=False))\n","LSTM3.add(Dense(1))\n","\n","LSTM3.compile(optimizer='adam', loss='mse')\n","LSTM3.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yoC1z34ORe7x"},"outputs":[],"source":["LSTM5 = Sequential()\n","LSTM5.add(LSTM(64, activation='relu', input_shape=(trainX_LSTM5.shape[1], trainX_LSTM5.shape[2]), return_sequences=True))\n","#LSTM5.add(Dropout(0.2))\n","#LSTM5.add(LSTM(32, activation='relu', return_sequences=True))\n","LSTM5.add(LSTM(64, activation='relu', return_sequences=True))\n","LSTM5.add(LSTM(64, activation='relu', return_sequences=False))\n","LSTM5.add(Dense(1))\n","\n","LSTM5.compile(optimizer='adam', loss='mse')\n","LSTM5.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPFy2VQDRn6j"},"outputs":[],"source":["LSTM7 = Sequential()\n","LSTM7.add(LSTM(64, activation='relu', input_shape=(trainX_LSTM7.shape[1], trainX_LSTM7.shape[2]), return_sequences=True))\n","#LSTM7.add(Dropout(0.2))\n","#LSTM7.add(LSTM(32, activation='relu', return_sequences=True))\n","LSTM7.add(LSTM(64, activation='relu', return_sequences=True))\n","LSTM7.add(LSTM(64, activation='relu', return_sequences=False))\n","LSTM7.add(Dense(1))\n","\n","LSTM7.compile(optimizer='adam', loss='mse')\n","LSTM7.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q8pJ8ge7VcNr"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"w77B3Kg8Ry3E"},"source":["## **Run**"]},{"cell_type":"markdown","source":["First, we define Earlystopping as a callback with patience set to 5. this means that training will stop when validation error does not reduce for 5 epochs."],"metadata":{"id":"UbxaxQxrKDMR"}},{"cell_type":"code","source":["callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"],"metadata":{"id":"G2XFweJobvN7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["With a batch size set to 64, callback set to our defined callback, and validation data set to our defined validation data split, we train the models for upto 200 epochs. Training may stop long before that thanks to earlystopping calllback"],"metadata":{"id":"8a9165KxKLTJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ggAQHkIJkM01"},"outputs":[],"source":["# fit the model\n","history1 =LSTM1.fit(trainX_LSTM1, trainY_LSTM1, epochs=200, batch_size=64, validation_data=[valX_LSTM1, valY_LSTM1], verbose=2, callbacks=[callback])\n","\n","plt.plot(history1.history['loss'], label='Training loss')\n","plt.plot(history1.history['val_loss'], label='Validation loss')\n","plt.legend()"]},{"cell_type":"markdown","source":["same was done for all the lead times"],"metadata":{"id":"qeZq8-SKKOvN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9xB55osV_W5"},"outputs":[],"source":["history3 =LSTM3.fit(trainX_LSTM3, trainY_LSTM3, epochs=200, batch_size=64, validation_data=[valX_LSTM3, valY_LSTM3], verbose=2, callbacks=[callback])\n","\n","plt.plot(history3.history['loss'], label='Training loss')\n","plt.plot(history3.history['val_loss'], label='Validation loss')\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZxT95oduWIDx"},"outputs":[],"source":["history5 =LSTM5.fit(trainX_LSTM5, trainY_LSTM5, epochs=200, batch_size=64, validation_data=[valX_LSTM5, valY_LSTM5], verbose=2, callbacks=[callback])\n","\n","plt.plot(history5.history['loss'], label='Training loss')\n","plt.plot(history5.history['val_loss'], label='Validation loss')\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N5AG3FgdWSPq"},"outputs":[],"source":["history7 =LSTM7.fit(trainX_LSTM7, trainY_LSTM7, epochs=200, batch_size=64, validation_data=[valX_LSTM7, valY_LSTM7], verbose=2, callbacks=[callback])\n","\n","plt.plot(history7.history['loss'], label='Training loss')\n","plt.plot(history7.history['val_loss'], label='Validation loss')\n","plt.legend()"]},{"cell_type":"markdown","metadata":{"id":"2gu0a-DJUrJ9"},"source":["## **prediction**"]},{"cell_type":"markdown","source":["It's time to make some predictions using our held out test dataset. we also use the train and validation dataset to calculate trianing and validation errors"],"metadata":{"id":"dW3L4P5TKYBt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Anb5e8Ln6TnT"},"outputs":[],"source":["trainpredictLSTM1 = LSTM1.predict(trainX_LSTM1)\n","valpredictLSTM1 = LSTM1.predict(valX_LSTM1)\n","testpredictLSTM1 = LSTM1.predict(testX_LSTM1)\n","\n","trainpredictLSTM3 = LSTM3.predict(trainX_LSTM3)\n","valpredictLSTM3 = LSTM3.predict(valX_LSTM3)\n","testpredictLSTM3 = LSTM3.predict(testX_LSTM3)\n","\n","trainpredictLSTM5 = LSTM5.predict(trainX_LSTM5)\n","valpredictLSTM5 = LSTM5.predict(valX_LSTM5)\n","testpredictLSTM5 = LSTM5.predict(testX_LSTM5)\n","\n","trainpredictLSTM7 = LSTM7.predict(trainX_LSTM7)\n","valpredictLSTM7 = LSTM7.predict(valX_LSTM7)\n","testpredictLSTM7 = LSTM7.predict(testX_LSTM7)"]},{"cell_type":"markdown","metadata":{"id":"7MunhshHcNAt"},"source":["## **Evaluation**"]},{"cell_type":"markdown","source":["Now we calculate RMSE values for train, test and validation datasets"],"metadata":{"id":"3cICCtgoKmqJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tN6XzKnPzb3B"},"outputs":[],"source":["trainScoreLSTM1 = math.sqrt(mean_squared_error(trainY_LSTM1, trainpredictLSTM1))\n","print('Train Score 1: %.2f RMSE' % (trainScoreLSTM1))\n","valScoreLSTM1 = math.sqrt(mean_squared_error(valY_LSTM1, valpredictLSTM1))\n","print('val Score 1: %.2f RMSE' % (valScoreLSTM1))\n","testScoreLSTM1 = math.sqrt(mean_squared_error(testY_LSTM1, testpredictLSTM1))\n","print('Test Score 1: %.2f RMSE' % (testScoreLSTM1))\n","\n","trainScoreLSTM3 = math.sqrt(mean_squared_error(trainY_LSTM3, trainpredictLSTM3))\n","print('Train Score 3: %.2f RMSE' % (trainScoreLSTM3))\n","valScoreLSTM3 = math.sqrt(mean_squared_error(valY_LSTM3, valpredictLSTM3))\n","print('val Score 3: %.2f RMSE' % (valScoreLSTM3))\n","testScoreLSTM3 = math.sqrt(mean_squared_error(testY_LSTM3, testpredictLSTM3))\n","print('Test Score 3: %.2f RMSE' % (testScoreLSTM3))\n","\n","trainScoreLSTM5 = math.sqrt(mean_squared_error(trainY_LSTM5, trainpredictLSTM5))\n","print('Train Score 5: %.2f RMSE' % (trainScoreLSTM5))\n","valScoreLSTM5 = math.sqrt(mean_squared_error(valY_LSTM5, valpredictLSTM5))\n","print('val Score 5: %.2f RMSE' % (valScoreLSTM5))\n","testScoreLSTM5 = math.sqrt(mean_squared_error(testY_LSTM5, testpredictLSTM5))\n","print('Test Score 5: %.2f RMSE' % (testScoreLSTM5))\n","\n","trainScoreLSTM7 = math.sqrt(mean_squared_error(trainY_LSTM7, trainpredictLSTM7))\n","print('Train Score 7: %.2f RMSE' % (trainScoreLSTM7))\n","valScoreLSTM7 = math.sqrt(mean_squared_error(valY_LSTM7, valpredictLSTM7))\n","print('val Score 7: %.2f RMSE' % (valScoreLSTM7))\n","testScoreLSTM7 = math.sqrt(mean_squared_error(testY_LSTM7, testpredictLSTM7))\n","print('Test Score 7: %.2f RMSE' % (testScoreLSTM7))\n","\n"]},{"cell_type":"markdown","source":["Now we calculate r2 values for train, test and validation datasets"],"metadata":{"id":"ZDGJuJUXK0Zt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ssrYlI4zbzJ"},"outputs":[],"source":["trainr2_LSTM1 =r2_score(trainY_LSTM1, trainpredictLSTM1)\n","print('Train Score 1: %.2f RMSE' % (trainr2_LSTM1))\n","valr2_LSTM1 =r2_score(valY_LSTM1, valpredictLSTM1)\n","print('val Score 1: %.2f RMSE' % (valr2_LSTM1))\n","testr2_LSTM1 =r2_score(testY_LSTM1, testpredictLSTM1)\n","print('Test Score 1: %.2f RMSE' % (testr2_LSTM1))\n","\n","trainr2_LSTM3 =r2_score(trainY_LSTM3, trainpredictLSTM3)\n","print('Train Score 3: %.2f RMSE' % (trainr2_LSTM3))\n","valr2_LSTM3 =r2_score(valY_LSTM3, valpredictLSTM3)\n","print('val Score 3: %.2f RMSE' % (valr2_LSTM3))\n","testr2_LSTM3 =r2_score(testY_LSTM3, testpredictLSTM3)\n","print('Test Score 3: %.2f RMSE' % (testr2_LSTM3))\n","\n","trainr2_LSTM5 =r2_score(trainY_LSTM5, trainpredictLSTM5)\n","print('Train Score 5: %.2f RMSE' % (trainr2_LSTM5))\n","valr2_LSTM5 =r2_score(valY_LSTM5, valpredictLSTM5)\n","print('val Score 5: %.2f RMSE' % (valr2_LSTM5))\n","testr2_LSTM5 =r2_score(testY_LSTM5, testpredictLSTM5)\n","print('Test Score 5: %.2f RMSE' % (testr2_LSTM5))\n","\n","trainr2_LSTM7 =r2_score(trainY_LSTM7, trainpredictLSTM7)\n","print('Train Score 7: %.2f RMSE' % (trainr2_LSTM7))\n","valr2_LSTM7 =r2_score(valY_LSTM7, valpredictLSTM7)\n","print('val Score 7: %.2f RMSE' % (valr2_LSTM7))\n","testr2_LSTM7 =r2_score(testY_LSTM7, testpredictLSTM7)\n","print('Test Score 7: %.2f RMSE' % (testr2_LSTM7))"]},{"cell_type":"markdown","source":["We now update the rmse and r2 dataframe by including scores for our LSTM model"],"metadata":{"id":"VVf6EHkfK45w"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QuhSFYnfZi4n"},"outputs":[],"source":["rmse_LSTMvals={'LSTM':[trainScoreLSTM1,valScoreLSTM1,testScoreLSTM1,trainScoreLSTM3,valScoreLSTM3,testScoreLSTM3,trainScoreLSTM5,valScoreLSTM5,testScoreLSTM5,trainScoreLSTM7,valScoreLSTM7,testScoreLSTM7]}\n","df_rmse_LSTM=pd.DataFrame(rmse_LSTMvals)\n","df_rmse=df_rmse.join(df_rmse_LSTM)\n","\n","r2_LSTMvals={'LSTM':[trainr2_LSTM1,valr2_LSTM1,testr2_LSTM1,trainr2_LSTM3,valr2_LSTM3,testr2_LSTM3,trainr2_LSTM5,valr2_LSTM5,testr2_LSTM5,trainr2_LSTM7,valr2_LSTM7,testr2_LSTM7]}\n","df_r2_LSTM=pd.DataFrame(r2_LSTMvals)\n","df_r2=df_r2.join(df_r2_LSTM)\n"]},{"cell_type":"markdown","metadata":{"id":"VBBa8OM2bOcq"},"source":["## **Save LSTM models**"]},{"cell_type":"markdown","source":["Time to save the new models for further use later"],"metadata":{"id":"7qhgKgTBLN8o"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mUUw_PC9ZsBe"},"outputs":[],"source":["LSTM1.save('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/LSTM/LSTM1.h5')\n","\n","LSTM3.save('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/LSTM/LSTM3.h5')\n","\n","LSTM5.save('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/LSTM/LSTM5.h5')\n","\n","LSTM7.save('/content/drive/MyDrive/Thesis/SavedModels/'+vars+'/LSTM/LSTM7.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"goJ656MjuxyJ"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"G9EWYyg1Px1C"},"source":["# **Error dataframes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3SJ2NSwkSBHc"},"outputs":[],"source":["df_rmse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYsuZkESca9m"},"outputs":[],"source":["df_r2"]},{"cell_type":"markdown","metadata":{"id":"EAnR8ZC_LJcT"},"source":["# **Monsoon Flood**"]},{"cell_type":"markdown","metadata":{"id":"kFztqopWCzPg"},"source":["## **2017 Monsoon**"]},{"cell_type":"markdown","source":["First we determine the water levels for monsoon season 2017. "],"metadata":{"id":"O2uNeZE9K6Wk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwYUw41QBJQP"},"outputs":[],"source":["WL2017Monsoon = testY1[-1310:-1173]\n","WL2017Monsoon"]},{"cell_type":"markdown","source":["Now we predict the water levels for the 2017 monsoon flood period using our trained models for different lead times and calculate the RMSE values for each prediction.\n","\n","Finally we create a dataframe with the RMSE values for 2017 monsoon flood"],"metadata":{"id":"rlGaKnoWL3uV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yI0cW2k0Nfh_"},"outputs":[],"source":["predictANNY1_2017Monsoon=testpredictANN1[-1310:-1173].reshape(-1)\n","predictANNY3_2017Monsoon=testpredictANN3[-1310:-1173].reshape(-1)\n","predictANNY5_2017Monsoon=testpredictANN5[-1310:-1173].reshape(-1)\n","predictANNY7_2017Monsoon=testpredictANN7[-1310:-1173].reshape(-1)\n","\n","rmseANN1day2017Monsoon= math.sqrt(mean_squared_error(predictANNY1_2017Monsoon,WL2017Monsoon))\n","print('RMSE ANN 1day 2017Monsoon = %.2f' %(rmseANN1day2017Monsoon))\n","\n","rmseANN3day2017Monsoon= math.sqrt(mean_squared_error(predictANNY3_2017Monsoon,WL2017Monsoon))\n","print('RMSE ANN 3day 2017Monsoon = %.2f' %(rmseANN3day2017Monsoon))\n","\n","rmseANN5day2017Monsoon= math.sqrt(mean_squared_error(predictANNY5_2017Monsoon,WL2017Monsoon))\n","print('RMSE ANN 5day 2017Monsoon = %.2f' %(rmseANN5day2017Monsoon))\n","\n","rmseANN7day2017Monsoon= math.sqrt(mean_squared_error(predictANNY7_2017Monsoon,WL2017Monsoon))\n","print('RMSE ANN 7day 2017Monsoon = %.2f' %(rmseANN7day2017Monsoon))\n","\n","\n","predictRFY1_2017Monsoon=testpredictRF1[-1310:-1173].reshape(-1)\n","predictRFY3_2017Monsoon=testpredictRF3[-1310:-1173].reshape(-1)\n","predictRFY5_2017Monsoon=testpredictRF5[-1310:-1173].reshape(-1)\n","predictRFY7_2017Monsoon=testpredictRF7[-1310:-1173].reshape(-1)\n","\n","rmseRF1day2017Monsoon= math.sqrt(mean_squared_error(predictRFY1_2017Monsoon,WL2017Monsoon))\n","print('RMSE RF 1day 2017Monsoon = %.2f' %(rmseRF1day2017Monsoon))\n","\n","rmseRF3day2017Monsoon= math.sqrt(mean_squared_error(predictRFY3_2017Monsoon,WL2017Monsoon))\n","print('RMSE RF 3day 2017Monsoon = %.2f' %(rmseRF3day2017Monsoon))\n","\n","rmseRF5day2017Monsoon= math.sqrt(mean_squared_error(predictRFY5_2017Monsoon,WL2017Monsoon))\n","print('RMSE RF 5day 2017Monsoon = %.2f' %(rmseRF5day2017Monsoon))\n","\n","rmseRF7day2017Monsoon= math.sqrt(mean_squared_error(predictRFY7_2017Monsoon,WL2017Monsoon))\n","print('RMSE RF 7day 2017Monsoon = %.2f' %(rmseRF7day2017Monsoon))\n","\n","\n","predictCBY1_2017Monsoon=testpredictCB1[-1310:-1173].reshape(-1)\n","predictCBY3_2017Monsoon=testpredictCB3[-1310:-1173].reshape(-1)\n","predictCBY5_2017Monsoon=testpredictCB5[-1310:-1173].reshape(-1)\n","predictCBY7_2017Monsoon=testpredictCB7[-1310:-1173].reshape(-1)\n","\n","rmseCB1day2017Monsoon= math.sqrt(mean_squared_error(predictCBY1_2017Monsoon,WL2017Monsoon))\n","print('RMSE CB 1day 2017Monsoon = %.2f' %(rmseCB1day2017Monsoon))\n","\n","rmseCB3day2017Monsoon= math.sqrt(mean_squared_error(predictCBY3_2017Monsoon,WL2017Monsoon))\n","print('RMSE CB 3day 2017Monsoon = %.2f' %(rmseCB3day2017Monsoon))\n","\n","rmseCB5day2017Monsoon= math.sqrt(mean_squared_error(predictCBY5_2017Monsoon,WL2017Monsoon))\n","print('RMSE CB 5day 2017Monsoon = %.2f' %(rmseCB5day2017Monsoon))\n","\n","rmseCB7day2017Monsoon= math.sqrt(mean_squared_error(predictCBY7_2017Monsoon,WL2017Monsoon))\n","print('RMSE CB 7day 2017Monsoon = %.2f' %(rmseCB7day2017Monsoon))\n","\n","\n","predictLSTMY1_2017Monsoon=testpredictLSTM1[-1310:-1173].reshape(-1)\n","predictLSTMY3_2017Monsoon=testpredictLSTM3[-1310:-1173].reshape(-1)\n","predictLSTMY5_2017Monsoon=testpredictLSTM5[-1310:-1173].reshape(-1)\n","predictLSTMY7_2017Monsoon=testpredictLSTM7[-1310:-1173].reshape(-1)\n","\n","rmseLSTM1day2017Monsoon= math.sqrt(mean_squared_error(predictLSTMY1_2017Monsoon,WL2017Monsoon))\n","print('RMSE LSTM 1day 2017Monsoon = %.2f' %(rmseLSTM1day2017Monsoon))\n","\n","rmseLSTM3day2017Monsoon= math.sqrt(mean_squared_error(predictLSTMY3_2017Monsoon,WL2017Monsoon))\n","print('RMSE LSTM 3day 2017Monsoon = %.2f' %(rmseLSTM3day2017Monsoon))\n","\n","rmseLSTM5day2017Monsoon= math.sqrt(mean_squared_error(predictLSTMY5_2017Monsoon,WL2017Monsoon))\n","print('RMSE LSTM 5day 2017Monsoon = %.2f' %(rmseLSTM5day2017Monsoon))\n","\n","rmseLSTM7day2017Monsoon= math.sqrt(mean_squared_error(predictLSTMY7_2017Monsoon,WL2017Monsoon))\n","print('RMSE LSTM 7day 2017Monsoon = %.2f' %(rmseLSTM7day2017Monsoon))\n","\n","\n","rmse_2017Monsoon={'ANN':[rmseANN1day2017Monsoon,rmseANN3day2017Monsoon,rmseANN5day2017Monsoon,rmseANN7day2017Monsoon], 'RF':[rmseRF1day2017Monsoon,rmseRF3day2017Monsoon,rmseRF5day2017Monsoon,rmseRF7day2017Monsoon], 'CB':[rmseCB1day2017Monsoon,rmseCB3day2017Monsoon,rmseCB5day2017Monsoon,rmseCB7day2017Monsoon], 'LSTM': [rmseLSTM1day2017Monsoon,rmseLSTM3day2017Monsoon,rmseLSTM5day2017Monsoon,rmseLSTM7day2017Monsoon]}\n","df_rmse_2017Monsoon=pd.DataFrame(rmse_2017Monsoon)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p5s3YLvMElrn"},"outputs":[],"source":["df_rmse_2017Monsoon"]},{"cell_type":"markdown","metadata":{"id":"ZlvyPsZQMwN6"},"source":["## **2018 Monsson**"]},{"cell_type":"markdown","source":["NOw we determine the water levels for monsoon season 2018."],"metadata":{"id":"jAhtNwQcMyvc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPsoEnnaIIPz"},"outputs":[],"source":["WL2018Monsoon = testY1[-1310+365:-1173+365]\n","WL2018Monsoon"]},{"cell_type":"markdown","source":["Now we predict the water levels for the 2018 monsoon flood period using our trained models for different lead times and calculate the RMSE values for each prediction.\n","\n","Finally we create a dataframe with the RMSE values for 2018 monsoon flood"],"metadata":{"id":"Wnjf1nXfM1Ss"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7yKgTcCnM1X1"},"outputs":[],"source":["predictANNY1_2018Monsoon=testpredictANN1[-1310+365:-1173+365].reshape(-1)\n","predictANNY3_2018Monsoon=testpredictANN3[-1310+365:-1173+365].reshape(-1)\n","predictANNY5_2018Monsoon=testpredictANN5[-1310+365:-1173+365].reshape(-1)\n","predictANNY7_2018Monsoon=testpredictANN7[-1310+365:-1173+365].reshape(-1)\n","\n","rmseANN1day2018Monsoon= math.sqrt(mean_squared_error(predictANNY1_2018Monsoon,WL2018Monsoon))\n","print('RMSE ANN 1day 2018Monsoon = %.2f' %(rmseANN1day2018Monsoon))\n","\n","rmseANN3day2018Monsoon= math.sqrt(mean_squared_error(predictANNY3_2018Monsoon,WL2018Monsoon))\n","print('RMSE ANN 3day 2018Monsoon = %.2f' %(rmseANN3day2018Monsoon))\n","\n","rmseANN5day2018Monsoon= math.sqrt(mean_squared_error(predictANNY5_2018Monsoon,WL2018Monsoon))\n","print('RMSE ANN 5day 2018Monsoon = %.2f' %(rmseANN5day2018Monsoon))\n","\n","rmseANN7day2018Monsoon= math.sqrt(mean_squared_error(predictANNY7_2018Monsoon,WL2018Monsoon))\n","print('RMSE ANN 7day 2018Monsoon = %.2f' %(rmseANN7day2018Monsoon))\n","\n","\n","predictRFY1_2018Monsoon=testpredictRF1[-1310+365:-1173+365].reshape(-1)\n","predictRFY3_2018Monsoon=testpredictRF3[-1310+365:-1173+365].reshape(-1)\n","predictRFY5_2018Monsoon=testpredictRF5[-1310+365:-1173+365].reshape(-1)\n","predictRFY7_2018Monsoon=testpredictRF7[-1310+365:-1173+365].reshape(-1)\n","\n","rmseRF1day2018Monsoon= math.sqrt(mean_squared_error(predictRFY1_2018Monsoon,WL2018Monsoon))\n","print('RMSE RF 1day 2018Monsoon = %.2f' %(rmseRF1day2018Monsoon))\n","\n","rmseRF3day2018Monsoon= math.sqrt(mean_squared_error(predictRFY3_2018Monsoon,WL2018Monsoon))\n","print('RMSE RF 3day 2018Monsoon = %.2f' %(rmseRF3day2018Monsoon))\n","\n","rmseRF5day2018Monsoon= math.sqrt(mean_squared_error(predictRFY5_2018Monsoon,WL2018Monsoon))\n","print('RMSE RF 5day 2018Monsoon = %.2f' %(rmseRF5day2018Monsoon))\n","\n","rmseRF7day2018Monsoon= math.sqrt(mean_squared_error(predictRFY7_2018Monsoon,WL2018Monsoon))\n","print('RMSE RF 7day 2018Monsoon = %.2f' %(rmseRF7day2018Monsoon))\n","\n","\n","predictCBY1_2018Monsoon=testpredictCB1[-1310+365:-1173+365].reshape(-1)\n","predictCBY3_2018Monsoon=testpredictCB3[-1310+365:-1173+365].reshape(-1)\n","predictCBY5_2018Monsoon=testpredictCB5[-1310+365:-1173+365].reshape(-1)\n","predictCBY7_2018Monsoon=testpredictCB7[-1310+365:-1173+365].reshape(-1)\n","\n","rmseCB1day2018Monsoon= math.sqrt(mean_squared_error(predictCBY1_2018Monsoon,WL2018Monsoon))\n","print('RMSE CB 1day 2018Monsoon = %.2f' %(rmseCB1day2018Monsoon))\n","\n","rmseCB3day2018Monsoon= math.sqrt(mean_squared_error(predictCBY3_2018Monsoon,WL2018Monsoon))\n","print('RMSE CB 3day 2018Monsoon = %.2f' %(rmseCB3day2018Monsoon))\n","\n","rmseCB5day2018Monsoon= math.sqrt(mean_squared_error(predictCBY5_2018Monsoon,WL2018Monsoon))\n","print('RMSE CB 5day 2018Monsoon = %.2f' %(rmseCB5day2018Monsoon))\n","\n","rmseCB7day2018Monsoon= math.sqrt(mean_squared_error(predictCBY7_2018Monsoon,WL2018Monsoon))\n","print('RMSE CB 7day 2018Monsoon = %.2f' %(rmseCB7day2018Monsoon))\n","\n","\n","predictLSTMY1_2018Monsoon=testpredictLSTM1[-1310+365:-1173+365].reshape(-1)\n","predictLSTMY3_2018Monsoon=testpredictLSTM3[-1310+365:-1173+365].reshape(-1)\n","predictLSTMY5_2018Monsoon=testpredictLSTM5[-1310+365:-1173+365].reshape(-1)\n","predictLSTMY7_2018Monsoon=testpredictLSTM7[-1310+365:-1173+365].reshape(-1)\n","\n","rmseLSTM1day2018Monsoon= math.sqrt(mean_squared_error(predictLSTMY1_2018Monsoon,WL2018Monsoon))\n","print('RMSE LSTM 1day 2018Monsoon = %.2f' %(rmseLSTM1day2018Monsoon))\n","\n","rmseLSTM3day2018Monsoon= math.sqrt(mean_squared_error(predictLSTMY3_2018Monsoon,WL2018Monsoon))\n","print('RMSE LSTM 3day 2018Monsoon = %.2f' %(rmseLSTM3day2018Monsoon))\n","\n","rmseLSTM5day2018Monsoon= math.sqrt(mean_squared_error(predictLSTMY5_2018Monsoon,WL2018Monsoon))\n","print('RMSE LSTM 5day 2018Monsoon = %.2f' %(rmseLSTM5day2018Monsoon))\n","\n","rmseLSTM7day2018Monsoon= math.sqrt(mean_squared_error(predictLSTMY7_2018Monsoon,WL2018Monsoon))\n","print('RMSE LSTM 7day 2018Monsoon = %.2f' %(rmseLSTM7day2018Monsoon))\n","\n","\n","rmse_2018Monsoon={'ANN':[rmseANN1day2018Monsoon,rmseANN3day2018Monsoon,rmseANN5day2018Monsoon,rmseANN7day2018Monsoon], 'RF':[rmseRF1day2018Monsoon,rmseRF3day2018Monsoon,rmseRF5day2018Monsoon,rmseRF7day2018Monsoon], 'CB':[rmseCB1day2018Monsoon,rmseCB3day2018Monsoon,rmseCB5day2018Monsoon,rmseCB7day2018Monsoon], 'LSTM': [rmseLSTM1day2018Monsoon,rmseLSTM3day2018Monsoon,rmseLSTM5day2018Monsoon,rmseLSTM7day2018Monsoon]}\n","df_rmse_2018Monsoon=pd.DataFrame(rmse_2018Monsoon)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-vTTJbJNGyr"},"outputs":[],"source":["df_rmse_2018Monsoon"]},{"cell_type":"markdown","metadata":{"id":"fmr3sl9iMMNV"},"source":["## **2019 Monsoon**"]},{"cell_type":"markdown","source":["Now we determine the water levels for monsoon season 2019."],"metadata":{"id":"7gJjzCT6NToE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tFkWjjbwMPJu"},"outputs":[],"source":["WL2019Monsoon = testY1[-1310+365+365:-1173+365+365]\n","WL2019Monsoon"]},{"cell_type":"markdown","source":["Now we predict the water levels for the 2019 monsoon flood period using our trained models for different lead times and calculate the RMSE values for each prediction.\n","\n","Finally we create a dataframe with the RMSE values for 2019 monsoon flood"],"metadata":{"id":"PmUsefPVM9ej"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UaIidkfZMgHR"},"outputs":[],"source":["predictANNY1_2019Monsoon=testpredictANN1[-1310+365+365:-1173+365+365].reshape(-1)\n","predictANNY3_2019Monsoon=testpredictANN3[-1310+365+365:-1173+365+365].reshape(-1)\n","predictANNY5_2019Monsoon=testpredictANN5[-1310+365+365:-1173+365+365].reshape(-1)\n","predictANNY7_2019Monsoon=testpredictANN7[-1310+365+365:-1173+365+365].reshape(-1)\n","\n","rmseANN1day2019Monsoon= math.sqrt(mean_squared_error(predictANNY1_2019Monsoon,WL2019Monsoon))\n","print('RMSE ANN 1day 2019Monsoon = %.2f' %(rmseANN1day2019Monsoon))\n","\n","rmseANN3day2019Monsoon= math.sqrt(mean_squared_error(predictANNY3_2019Monsoon,WL2019Monsoon))\n","print('RMSE ANN 3day 2019Monsoon = %.2f' %(rmseANN3day2019Monsoon))\n","\n","rmseANN5day2019Monsoon= math.sqrt(mean_squared_error(predictANNY5_2019Monsoon,WL2019Monsoon))\n","print('RMSE ANN 5day 2019Monsoon = %.2f' %(rmseANN5day2019Monsoon))\n","\n","rmseANN7day2019Monsoon= math.sqrt(mean_squared_error(predictANNY7_2019Monsoon,WL2019Monsoon))\n","print('RMSE ANN 7day 2019Monsoon = %.2f' %(rmseANN7day2019Monsoon))\n","\n","\n","predictRFY1_2019Monsoon=testpredictRF1[-1310+365+365:-1173+365+365].reshape(-1)\n","predictRFY3_2019Monsoon=testpredictRF3[-1310+365+365:-1173+365+365].reshape(-1)\n","predictRFY5_2019Monsoon=testpredictRF5[-1310+365+365:-1173+365+365].reshape(-1)\n","predictRFY7_2019Monsoon=testpredictRF7[-1310+365+365:-1173+365+365].reshape(-1)\n","\n","rmseRF1day2019Monsoon= math.sqrt(mean_squared_error(predictRFY1_2019Monsoon,WL2019Monsoon))\n","print('RMSE RF 1day 2019Monsoon = %.2f' %(rmseRF1day2019Monsoon))\n","\n","rmseRF3day2019Monsoon= math.sqrt(mean_squared_error(predictRFY3_2019Monsoon,WL2019Monsoon))\n","print('RMSE RF 3day 2019Monsoon = %.2f' %(rmseRF3day2019Monsoon))\n","\n","rmseRF5day2019Monsoon= math.sqrt(mean_squared_error(predictRFY5_2019Monsoon,WL2019Monsoon))\n","print('RMSE RF 5day 2019Monsoon = %.2f' %(rmseRF5day2019Monsoon))\n","\n","rmseRF7day2019Monsoon= math.sqrt(mean_squared_error(predictRFY7_2019Monsoon,WL2019Monsoon))\n","print('RMSE RF 7day 2019Monsoon = %.2f' %(rmseRF7day2019Monsoon))\n","\n","\n","predictCBY1_2019Monsoon=testpredictCB1[-1310+365+365:-1173+365+365].reshape(-1)\n","predictCBY3_2019Monsoon=testpredictCB3[-1310+365+365:-1173+365+365].reshape(-1)\n","predictCBY5_2019Monsoon=testpredictCB5[-1310+365+365:-1173+365+365].reshape(-1)\n","predictCBY7_2019Monsoon=testpredictCB7[-1310+365+365:-1173+365+365].reshape(-1)\n","\n","rmseCB1day2019Monsoon= math.sqrt(mean_squared_error(predictCBY1_2019Monsoon,WL2019Monsoon))\n","print('RMSE CB 1day 2019Monsoon = %.2f' %(rmseCB1day2019Monsoon))\n","\n","rmseCB3day2019Monsoon= math.sqrt(mean_squared_error(predictCBY3_2019Monsoon,WL2019Monsoon))\n","print('RMSE CB 3day 2019Monsoon = %.2f' %(rmseCB3day2019Monsoon))\n","\n","rmseCB5day2019Monsoon= math.sqrt(mean_squared_error(predictCBY5_2019Monsoon,WL2019Monsoon))\n","print('RMSE CB 5day 2019Monsoon = %.2f' %(rmseCB5day2019Monsoon))\n","\n","rmseCB7day2019Monsoon= math.sqrt(mean_squared_error(predictCBY7_2019Monsoon,WL2019Monsoon))\n","print('RMSE CB 7day 2019Monsoon = %.2f' %(rmseCB7day2019Monsoon))\n","\n","\n","predictLSTMY1_2019Monsoon=testpredictLSTM1[-1310+365+365:-1173+365+365].reshape(-1)\n","predictLSTMY3_2019Monsoon=testpredictLSTM3[-1310+365+365:-1173+365+365].reshape(-1)\n","predictLSTMY5_2019Monsoon=testpredictLSTM5[-1310+365+365:-1173+365+365].reshape(-1)\n","predictLSTMY7_2019Monsoon=testpredictLSTM7[-1310+365+365:-1173+365+365].reshape(-1)\n","\n","rmseLSTM1day2019Monsoon= math.sqrt(mean_squared_error(predictLSTMY1_2019Monsoon,WL2019Monsoon))\n","print('RMSE LSTM 1day 2019Monsoon = %.2f' %(rmseLSTM1day2019Monsoon))\n","\n","rmseLSTM3day2019Monsoon= math.sqrt(mean_squared_error(predictLSTMY3_2019Monsoon,WL2019Monsoon))\n","print('RMSE LSTM 3day 2019Monsoon = %.2f' %(rmseLSTM3day2019Monsoon))\n","\n","rmseLSTM5day2019Monsoon= math.sqrt(mean_squared_error(predictLSTMY5_2019Monsoon,WL2019Monsoon))\n","print('RMSE LSTM 5day 2019Monsoon = %.2f' %(rmseLSTM5day2019Monsoon))\n","\n","rmseLSTM7day2019Monsoon= math.sqrt(mean_squared_error(predictLSTMY7_2019Monsoon,WL2019Monsoon))\n","print('RMSE LSTM 7day 2019Monsoon = %.2f' %(rmseLSTM7day2019Monsoon))\n","\n","\n","rmse_2019Monsoon={'ANN':[rmseANN1day2019Monsoon,rmseANN3day2019Monsoon,rmseANN5day2019Monsoon,rmseANN7day2019Monsoon], 'RF':[rmseRF1day2019Monsoon,rmseRF3day2019Monsoon,rmseRF5day2019Monsoon,rmseRF7day2019Monsoon], 'CB':[rmseCB1day2019Monsoon,rmseCB3day2019Monsoon,rmseCB5day2019Monsoon,rmseCB7day2019Monsoon], 'LSTM': [rmseLSTM1day2019Monsoon,rmseLSTM3day2019Monsoon,rmseLSTM5day2019Monsoon,rmseLSTM7day2019Monsoon]}\n","df_rmse_2019Monsoon=pd.DataFrame(rmse_2019Monsoon)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSwSzLCWMi1g"},"outputs":[],"source":["df_rmse_2019Monsoon"]},{"cell_type":"markdown","metadata":{"id":"G76BVAGRLP9P"},"source":["## **2020 Monsson**"]},{"cell_type":"markdown","source":["we determine the water levels for monsoon season 2020."],"metadata":{"id":"x_BwfMgYNXRG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zmB_LWhOLfQY"},"outputs":[],"source":["WL2020Monsoon = testY1[-1310+365+365+366:-1173+365+365+366]\n","WL2020Monsoon"]},{"cell_type":"markdown","source":["Now we predict the water levels for the 2020 monsoon flood period using our trained models for different lead times and calculate the RMSE values for each prediction.\n","\n","Finally we create a dataframe with the RMSE values for 2020 monsoon flood"],"metadata":{"id":"81SxZOvKNAcA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpmnP99kLdtd"},"outputs":[],"source":["predictANNY1_2020Monsoon=testpredictANN1[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","predictANNY3_2020Monsoon=testpredictANN3[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","predictANNY5_2020Monsoon=testpredictANN5[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","predictANNY7_2020Monsoon=testpredictANN7[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","\n","rmseANN1day2020Monsoon= math.sqrt(mean_squared_error(predictANNY1_2020Monsoon,WL2020Monsoon))\n","print('RMSE ANN 1day 2020Monsoon = %.2f' %(rmseANN1day2020Monsoon))\n","\n","rmseANN3day2020Monsoon= math.sqrt(mean_squared_error(predictANNY3_2020Monsoon,WL2020Monsoon))\n","print('RMSE ANN 3day 2020Monsoon = %.2f' %(rmseANN3day2020Monsoon))\n","\n","rmseANN5day2020Monsoon= math.sqrt(mean_squared_error(predictANNY5_2020Monsoon,WL2020Monsoon))\n","print('RMSE ANN 5day 2020Monsoon = %.2f' %(rmseANN5day2020Monsoon))\n","\n","rmseANN7day2020Monsoon= math.sqrt(mean_squared_error(predictANNY7_2020Monsoon,WL2020Monsoon))\n","print('RMSE ANN 7day 2020Monsoon = %.2f' %(rmseANN7day2020Monsoon))\n","\n","\n","predictRFY1_2020Monsoon=testpredictRF1[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","predictRFY3_2020Monsoon=testpredictRF3[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","predictRFY5_2020Monsoon=testpredictRF5[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","predictRFY7_2020Monsoon=testpredictRF7[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","\n","rmseRF1day2020Monsoon= math.sqrt(mean_squared_error(predictRFY1_2020Monsoon,WL2020Monsoon))\n","print('RMSE RF 1day 2020Monsoon = %.2f' %(rmseRF1day2020Monsoon))\n","\n","rmseRF3day2020Monsoon= math.sqrt(mean_squared_error(predictRFY3_2020Monsoon,WL2020Monsoon))\n","print('RMSE RF 3day 2020Monsoon = %.2f' %(rmseRF3day2020Monsoon))\n","\n","rmseRF5day2020Monsoon= math.sqrt(mean_squared_error(predictRFY5_2020Monsoon,WL2020Monsoon))\n","print('RMSE RF 5day 2020Monsoon = %.2f' %(rmseRF5day2020Monsoon))\n","\n","rmseRF7day2020Monsoon= math.sqrt(mean_squared_error(predictRFY7_2020Monsoon,WL2020Monsoon))\n","print('RMSE RF 7day 2020Monsoon = %.2f' %(rmseRF7day2020Monsoon))\n","\n","\n","predictCBY1_2020Monsoon=testpredictCB1[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","predictCBY3_2020Monsoon=testpredictCB3[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","predictCBY5_2020Monsoon=testpredictCB5[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","predictCBY7_2020Monsoon=testpredictCB7[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","\n","rmseCB1day2020Monsoon= math.sqrt(mean_squared_error(predictCBY1_2020Monsoon,WL2020Monsoon))\n","print('RMSE CB 1day 2020Monsoon = %.2f' %(rmseCB1day2020Monsoon))\n","\n","rmseCB3day2020Monsoon= math.sqrt(mean_squared_error(predictCBY3_2020Monsoon,WL2020Monsoon))\n","print('RMSE CB 3day 2020Monsoon = %.2f' %(rmseCB3day2020Monsoon))\n","\n","rmseCB5day2020Monsoon= math.sqrt(mean_squared_error(predictCBY5_2020Monsoon,WL2020Monsoon))\n","print('RMSE CB 5day 2020Monsoon = %.2f' %(rmseCB5day2020Monsoon))\n","\n","rmseCB7day2020Monsoon= math.sqrt(mean_squared_error(predictCBY7_2020Monsoon,WL2020Monsoon))\n","print('RMSE CB 7day 2020Monsoon = %.2f' %(rmseCB7day2020Monsoon))\n","\n","\n","predictLSTMY1_2020Monsoon=testpredictLSTM1[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","predictLSTMY3_2020Monsoon=testpredictLSTM3[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","predictLSTMY5_2020Monsoon=testpredictLSTM5[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","predictLSTMY7_2020Monsoon=testpredictLSTM7[-1310+365+365+366:-1173+365+365+366].reshape(-1)\n","\n","rmseLSTM1day2020Monsoon= math.sqrt(mean_squared_error(predictLSTMY1_2020Monsoon,WL2020Monsoon))\n","print('RMSE LSTM 1day 2020Monsoon = %.2f' %(rmseLSTM1day2020Monsoon))\n","\n","rmseLSTM3day2020Monsoon= math.sqrt(mean_squared_error(predictLSTMY3_2020Monsoon,WL2020Monsoon))\n","print('RMSE LSTM 3day 2020Monsoon = %.2f' %(rmseLSTM3day2020Monsoon))\n","\n","rmseLSTM5day2020Monsoon= math.sqrt(mean_squared_error(predictLSTMY5_2020Monsoon,WL2020Monsoon))\n","print('RMSE LSTM 5day 2020Monsoon = %.2f' %(rmseLSTM5day2020Monsoon))\n","\n","rmseLSTM7day2020Monsoon= math.sqrt(mean_squared_error(predictLSTMY7_2020Monsoon,WL2020Monsoon))\n","print('RMSE LSTM 7day 2020Monsoon = %.2f' %(rmseLSTM7day2020Monsoon))\n","\n","\n","rmse_2020Monsoon={'ANN':[rmseANN1day2020Monsoon,rmseANN3day2020Monsoon,rmseANN5day2020Monsoon,rmseANN7day2020Monsoon], 'RF':[rmseRF1day2020Monsoon,rmseRF3day2020Monsoon,rmseRF5day2020Monsoon,rmseRF7day2020Monsoon], 'CB':[rmseCB1day2020Monsoon,rmseCB3day2020Monsoon,rmseCB5day2020Monsoon,rmseCB7day2020Monsoon], 'LSTM': [rmseLSTM1day2020Monsoon,rmseLSTM3day2020Monsoon,rmseLSTM5day2020Monsoon,rmseLSTM7day2020Monsoon]}\n","df_rmse_2020Monsoon=pd.DataFrame(rmse_2020Monsoon)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTsG2OilL8AC"},"outputs":[],"source":["df_rmse_2020Monsoon"]},{"cell_type":"markdown","metadata":{"id":"bvrddXy5NyHk"},"source":["## **Monsoon Flood df**"]},{"cell_type":"markdown","source":["Now we create a dataframe and merge all the RMSE values for the monsoon flood events."],"metadata":{"id":"gbEZ2lLcNZ0c"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bs9whs9ON10-"},"outputs":[],"source":["rmse_Monsoon = pd.concat([df_rmse_2017Monsoon, df_rmse_2018Monsoon, df_rmse_2019Monsoon, df_rmse_2020Monsoon ],axis=1)\n","rmse_Monsoon"]},{"cell_type":"markdown","metadata":{"id":"MxBRdlJeIJIG"},"source":["# **Flash Floods**"]},{"cell_type":"markdown","metadata":{"id":"-SW639CNCz5E"},"source":["## **Flash Flood 2017**"]},{"cell_type":"markdown","source":["we determine the water levels for Flash flood season 2017."],"metadata":{"id":"YKAP9nLeNlXP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"asJHiaLtCyeM"},"outputs":[],"source":["WL2017Flash = testY1[-1310-78:-1310]\n","WL2017Flash"]},{"cell_type":"markdown","source":["Now we predict the water levels for the 2017 Flash flood period using our trained models for different lead times and calculate the RMSE values for each prediction.\n","\n","Finally we create a dataframe with the RMSE values for 2017 Flash flood"],"metadata":{"id":"4msN4ADKOGnj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2mETYfbVES40"},"outputs":[],"source":["predictANNY1_2017Flash=testpredictANN1[-1310-78:-1310].reshape(-1)\n","predictANNY3_2017Flash=testpredictANN3[-1310-78:-1310].reshape(-1)\n","predictANNY5_2017Flash=testpredictANN5[-1310-78:-1310].reshape(-1)\n","predictANNY7_2017Flash=testpredictANN7[-1310-78:-1310].reshape(-1)\n","\n","rmseANN1day2017Flash= math.sqrt(mean_squared_error(predictANNY1_2017Flash,WL2017Flash))\n","print('RMSE ANN 1day 2017Flash = %.2f' %(rmseANN1day2017Flash))\n","\n","rmseANN3day2017Flash= math.sqrt(mean_squared_error(predictANNY3_2017Flash,WL2017Flash))\n","print('RMSE ANN 3day 2017Flash = %.2f' %(rmseANN3day2017Flash))\n","\n","rmseANN5day2017Flash= math.sqrt(mean_squared_error(predictANNY5_2017Flash,WL2017Flash))\n","print('RMSE ANN 5day 2017Flash = %.2f' %(rmseANN5day2017Flash))\n","\n","rmseANN7day2017Flash= math.sqrt(mean_squared_error(predictANNY7_2017Flash,WL2017Flash))\n","print('RMSE ANN 7day 2017Flash = %.2f' %(rmseANN7day2017Flash))\n","\n","\n","predictRFY1_2017Flash=testpredictRF1[-1310-78:-1310].reshape(-1)\n","predictRFY3_2017Flash=testpredictRF3[-1310-78:-1310].reshape(-1)\n","predictRFY5_2017Flash=testpredictRF5[-1310-78:-1310].reshape(-1)\n","predictRFY7_2017Flash=testpredictRF7[-1310-78:-1310].reshape(-1)\n","\n","rmseRF1day2017Flash= math.sqrt(mean_squared_error(predictRFY1_2017Flash,WL2017Flash))\n","print('RMSE RF 1day 2017Flash = %.2f' %(rmseRF1day2017Flash))\n","\n","rmseRF3day2017Flash= math.sqrt(mean_squared_error(predictRFY3_2017Flash,WL2017Flash))\n","print('RMSE RF 3day 2017Flash = %.2f' %(rmseRF3day2017Flash))\n","\n","rmseRF5day2017Flash= math.sqrt(mean_squared_error(predictRFY5_2017Flash,WL2017Flash))\n","print('RMSE RF 5day 2017Flash = %.2f' %(rmseRF5day2017Flash))\n","\n","rmseRF7day2017Flash= math.sqrt(mean_squared_error(predictRFY7_2017Flash,WL2017Flash))\n","print('RMSE RF 7day 2017Flash = %.2f' %(rmseRF7day2017Flash))\n","\n","\n","predictCBY1_2017Flash=testpredictCB1[-1310-78:-1310].reshape(-1)\n","predictCBY3_2017Flash=testpredictCB3[-1310-78:-1310].reshape(-1)\n","predictCBY5_2017Flash=testpredictCB5[-1310-78:-1310].reshape(-1)\n","predictCBY7_2017Flash=testpredictCB7[-1310-78:-1310].reshape(-1)\n","\n","rmseCB1day2017Flash= math.sqrt(mean_squared_error(predictCBY1_2017Flash,WL2017Flash))\n","print('RMSE CB 1day 2017Flash = %.2f' %(rmseCB1day2017Flash))\n","\n","rmseCB3day2017Flash= math.sqrt(mean_squared_error(predictCBY3_2017Flash,WL2017Flash))\n","print('RMSE CB 3day 2017Flash = %.2f' %(rmseCB3day2017Flash))\n","\n","rmseCB5day2017Flash= math.sqrt(mean_squared_error(predictCBY5_2017Flash,WL2017Flash))\n","print('RMSE CB 5day 2017Flash = %.2f' %(rmseCB5day2017Flash))\n","\n","rmseCB7day2017Flash= math.sqrt(mean_squared_error(predictCBY7_2017Flash,WL2017Flash))\n","print('RMSE CB 7day 2017Flash = %.2f' %(rmseCB7day2017Flash))\n","\n","\n","predictLSTMY1_2017Flash=testpredictLSTM1[-1310-78:-1310].reshape(-1)\n","predictLSTMY3_2017Flash=testpredictLSTM3[-1310-78:-1310].reshape(-1)\n","predictLSTMY5_2017Flash=testpredictLSTM5[-1310-78:-1310].reshape(-1)\n","predictLSTMY7_2017Flash=testpredictLSTM7[-1310-78:-1310].reshape(-1)\n","\n","rmseLSTM1day2017Flash= math.sqrt(mean_squared_error(predictLSTMY1_2017Flash,WL2017Flash))\n","print('RMSE LSTM 1day 2017Flash = %.2f' %(rmseLSTM1day2017Flash))\n","\n","rmseLSTM3day2017Flash= math.sqrt(mean_squared_error(predictLSTMY3_2017Flash,WL2017Flash))\n","print('RMSE LSTM 3day 2017Flash = %.2f' %(rmseLSTM3day2017Flash))\n","\n","rmseLSTM5day2017Flash= math.sqrt(mean_squared_error(predictLSTMY5_2017Flash,WL2017Flash))\n","print('RMSE LSTM 5day 2017Flash = %.2f' %(rmseLSTM5day2017Flash))\n","\n","rmseLSTM7day2017Flash= math.sqrt(mean_squared_error(predictLSTMY7_2017Flash,WL2017Flash))\n","print('RMSE LSTM 7day 2017Flash = %.2f' %(rmseLSTM7day2017Flash))\n","\n","\n","rmse_2017Flash={'ANN':[rmseANN1day2017Flash,rmseANN3day2017Flash,rmseANN5day2017Flash,rmseANN7day2017Flash], 'RF':[rmseRF1day2017Flash,rmseRF3day2017Flash,rmseRF5day2017Flash,rmseRF7day2017Flash], 'CB':[rmseCB1day2017Flash,rmseCB3day2017Flash,rmseCB5day2017Flash,rmseCB7day2017Flash], 'LSTM': [rmseLSTM1day2017Flash,rmseLSTM3day2017Flash,rmseLSTM5day2017Flash,rmseLSTM7day2017Flash]}\n","df_rmse_2017Flash=pd.DataFrame(rmse_2017Flash)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9DpNPjPwFkZD"},"outputs":[],"source":["df_rmse_2017Flash"]},{"cell_type":"markdown","metadata":{"id":"mBvLE4sFFsbX"},"source":["## **Flash Flood 2018**"]},{"cell_type":"markdown","source":["we determine the water levels for Flash flood season 2018."],"metadata":{"id":"PZeO_dRYNt48"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xugq6LJWFr6S"},"outputs":[],"source":["WL2018Flash = testY1[-1310-78+365:-1310+365]\n","WL2018Flash"]},{"cell_type":"markdown","source":["Now we predict the water levels for the 2018 Flash flood period using our trained models for different lead times and calculate the RMSE values for each prediction.\n","\n","Finally we create a dataframe with the RMSE values for 2018 Flash flood"],"metadata":{"id":"Buh27EGJODdL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dzp5i72MGa22"},"outputs":[],"source":["predictANNY1_2018Flash=testpredictANN1[-1310-78+365:-1310+365].reshape(-1)\n","predictANNY3_2018Flash=testpredictANN3[-1310-78+365:-1310+365].reshape(-1)\n","predictANNY5_2018Flash=testpredictANN5[-1310-78+365:-1310+365].reshape(-1)\n","predictANNY7_2018Flash=testpredictANN7[-1310-78+365:-1310+365].reshape(-1)\n","\n","rmseANN1day2018Flash= math.sqrt(mean_squared_error(predictANNY1_2018Flash,WL2018Flash))\n","print('RMSE ANN 1day 2018Flash = %.2f' %(rmseANN1day2018Flash))\n","\n","rmseANN3day2018Flash= math.sqrt(mean_squared_error(predictANNY3_2018Flash,WL2018Flash))\n","print('RMSE ANN 3day 2018Flash = %.2f' %(rmseANN3day2018Flash))\n","\n","rmseANN5day2018Flash= math.sqrt(mean_squared_error(predictANNY5_2018Flash,WL2018Flash))\n","print('RMSE ANN 5day 2018Flash = %.2f' %(rmseANN5day2018Flash))\n","\n","rmseANN7day2018Flash= math.sqrt(mean_squared_error(predictANNY7_2018Flash,WL2018Flash))\n","print('RMSE ANN 7day 2018Flash = %.2f' %(rmseANN7day2018Flash))\n","\n","\n","predictRFY1_2018Flash=testpredictRF1[-1310-78+365:-1310+365].reshape(-1)\n","predictRFY3_2018Flash=testpredictRF3[-1310-78+365:-1310+365].reshape(-1)\n","predictRFY5_2018Flash=testpredictRF5[-1310-78+365:-1310+365].reshape(-1)\n","predictRFY7_2018Flash=testpredictRF7[-1310-78+365:-1310+365].reshape(-1)\n","\n","rmseRF1day2018Flash= math.sqrt(mean_squared_error(predictRFY1_2018Flash,WL2018Flash))\n","print('RMSE RF 1day 2018Flash = %.2f' %(rmseRF1day2018Flash))\n","\n","rmseRF3day2018Flash= math.sqrt(mean_squared_error(predictRFY3_2018Flash,WL2018Flash))\n","print('RMSE RF 3day 2018Flash = %.2f' %(rmseRF3day2018Flash))\n","\n","rmseRF5day2018Flash= math.sqrt(mean_squared_error(predictRFY5_2018Flash,WL2018Flash))\n","print('RMSE RF 5day 2018Flash = %.2f' %(rmseRF5day2018Flash))\n","\n","rmseRF7day2018Flash= math.sqrt(mean_squared_error(predictRFY7_2018Flash,WL2018Flash))\n","print('RMSE RF 7day 2018Flash = %.2f' %(rmseRF7day2018Flash))\n","\n","\n","predictCBY1_2018Flash=testpredictCB1[-1310-78+365:-1310+365].reshape(-1)\n","predictCBY3_2018Flash=testpredictCB3[-1310-78+365:-1310+365].reshape(-1)\n","predictCBY5_2018Flash=testpredictCB5[-1310-78+365:-1310+365].reshape(-1)\n","predictCBY7_2018Flash=testpredictCB7[-1310-78+365:-1310+365].reshape(-1)\n","\n","rmseCB1day2018Flash= math.sqrt(mean_squared_error(predictCBY1_2018Flash,WL2018Flash))\n","print('RMSE CB 1day 2018Flash = %.2f' %(rmseCB1day2018Flash))\n","\n","rmseCB3day2018Flash= math.sqrt(mean_squared_error(predictCBY3_2018Flash,WL2018Flash))\n","print('RMSE CB 3day 2018Flash = %.2f' %(rmseCB3day2018Flash))\n","\n","rmseCB5day2018Flash= math.sqrt(mean_squared_error(predictCBY5_2018Flash,WL2018Flash))\n","print('RMSE CB 5day 2018Flash = %.2f' %(rmseCB5day2018Flash))\n","\n","rmseCB7day2018Flash= math.sqrt(mean_squared_error(predictCBY7_2018Flash,WL2018Flash))\n","print('RMSE CB 7day 2018Flash = %.2f' %(rmseCB7day2018Flash))\n","\n","\n","predictLSTMY1_2018Flash=testpredictLSTM1[-1310-78+365:-1310+365].reshape(-1)\n","predictLSTMY3_2018Flash=testpredictLSTM3[-1310-78+365:-1310+365].reshape(-1)\n","predictLSTMY5_2018Flash=testpredictLSTM5[-1310-78+365:-1310+365].reshape(-1)\n","predictLSTMY7_2018Flash=testpredictLSTM7[-1310-78+365:-1310+365].reshape(-1)\n","\n","rmseLSTM1day2018Flash= math.sqrt(mean_squared_error(predictLSTMY1_2018Flash,WL2018Flash))\n","print('RMSE LSTM 1day 2018Flash = %.2f' %(rmseLSTM1day2018Flash))\n","\n","rmseLSTM3day2018Flash= math.sqrt(mean_squared_error(predictLSTMY3_2018Flash,WL2018Flash))\n","print('RMSE LSTM 3day 2018Flash = %.2f' %(rmseLSTM3day2018Flash))\n","\n","rmseLSTM5day2018Flash= math.sqrt(mean_squared_error(predictLSTMY5_2018Flash,WL2018Flash))\n","print('RMSE LSTM 5day 2018Flash = %.2f' %(rmseLSTM5day2018Flash))\n","\n","rmseLSTM7day2018Flash= math.sqrt(mean_squared_error(predictLSTMY7_2018Flash,WL2018Flash))\n","print('RMSE LSTM 7day 2018Flash = %.2f' %(rmseLSTM7day2018Flash))\n","\n","\n","rmse_2018Flash={'ANN':[rmseANN1day2018Flash,rmseANN3day2018Flash,rmseANN5day2018Flash,rmseANN7day2018Flash], 'RF':[rmseRF1day2018Flash,rmseRF3day2018Flash,rmseRF5day2018Flash,rmseRF7day2018Flash], 'CB':[rmseCB1day2018Flash,rmseCB3day2018Flash,rmseCB5day2018Flash,rmseCB7day2018Flash], 'LSTM': [rmseLSTM1day2018Flash,rmseLSTM3day2018Flash,rmseLSTM5day2018Flash,rmseLSTM7day2018Flash]}\n","df_rmse_2018Flash=pd.DataFrame(rmse_2018Flash)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wuZjzeXxGcEs"},"outputs":[],"source":["df_rmse_2018Flash"]},{"cell_type":"markdown","metadata":{"id":"oP-Ayqj0GlME"},"source":["## **Flash Flood 2019**"]},{"cell_type":"markdown","source":["we determine the water levels for Flash flood season 2019."],"metadata":{"id":"w4c_0KuuNv5N"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xR4xZyu1GkVM"},"outputs":[],"source":["WL2019Flash = testY1[-1310-78+365+365:-1310+365+365]\n","WL2019Flash"]},{"cell_type":"markdown","source":["Now we predict the water levels for the 2019 Flash flood period using our trained models for different lead times and calculate the RMSE values for each prediction.\n","\n","Finally we create a dataframe with the RMSE values for 2019 Flash flood"],"metadata":{"id":"Iz9Yx4D8N-jl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWtISDSnHBL_"},"outputs":[],"source":["predictANNY1_2019Flash=testpredictANN1[-1310-78+365+365:-1310+365+365].reshape(-1)\n","predictANNY3_2019Flash=testpredictANN3[-1310-78+365+365:-1310+365+365].reshape(-1)\n","predictANNY5_2019Flash=testpredictANN5[-1310-78+365+365:-1310+365+365].reshape(-1)\n","predictANNY7_2019Flash=testpredictANN7[-1310-78+365+365:-1310+365+365].reshape(-1)\n","\n","rmseANN1day2019Flash= math.sqrt(mean_squared_error(predictANNY1_2019Flash,WL2019Flash))\n","print('RMSE ANN 1day 2019Flash = %.2f' %(rmseANN1day2019Flash))\n","\n","rmseANN3day2019Flash= math.sqrt(mean_squared_error(predictANNY3_2019Flash,WL2019Flash))\n","print('RMSE ANN 3day 2019Flash = %.2f' %(rmseANN3day2019Flash))\n","\n","rmseANN5day2019Flash= math.sqrt(mean_squared_error(predictANNY5_2019Flash,WL2019Flash))\n","print('RMSE ANN 5day 2019Flash = %.2f' %(rmseANN5day2019Flash))\n","\n","rmseANN7day2019Flash= math.sqrt(mean_squared_error(predictANNY7_2019Flash,WL2019Flash))\n","print('RMSE ANN 7day 2019Flash = %.2f' %(rmseANN7day2019Flash))\n","\n","\n","predictRFY1_2019Flash=testpredictRF1[-1310-78+365+365:-1310+365+365].reshape(-1)\n","predictRFY3_2019Flash=testpredictRF3[-1310-78+365+365:-1310+365+365].reshape(-1)\n","predictRFY5_2019Flash=testpredictRF5[-1310-78+365+365:-1310+365+365].reshape(-1)\n","predictRFY7_2019Flash=testpredictRF7[-1310-78+365+365:-1310+365+365].reshape(-1)\n","\n","rmseRF1day2019Flash= math.sqrt(mean_squared_error(predictRFY1_2019Flash,WL2019Flash))\n","print('RMSE RF 1day 2019Flash = %.2f' %(rmseRF1day2019Flash))\n","\n","rmseRF3day2019Flash= math.sqrt(mean_squared_error(predictRFY3_2019Flash,WL2019Flash))\n","print('RMSE RF 3day 2019Flash = %.2f' %(rmseRF3day2019Flash))\n","\n","rmseRF5day2019Flash= math.sqrt(mean_squared_error(predictRFY5_2019Flash,WL2019Flash))\n","print('RMSE RF 5day 2019Flash = %.2f' %(rmseRF5day2019Flash))\n","\n","rmseRF7day2019Flash= math.sqrt(mean_squared_error(predictRFY7_2019Flash,WL2019Flash))\n","print('RMSE RF 7day 2019Flash = %.2f' %(rmseRF7day2019Flash))\n","\n","\n","predictCBY1_2019Flash=testpredictCB1[-1310-78+365+365:-1310+365+365].reshape(-1)\n","predictCBY3_2019Flash=testpredictCB3[-1310-78+365+365:-1310+365+365].reshape(-1)\n","predictCBY5_2019Flash=testpredictCB5[-1310-78+365+365:-1310+365+365].reshape(-1)\n","predictCBY7_2019Flash=testpredictCB7[-1310-78+365+365:-1310+365+365].reshape(-1)\n","\n","rmseCB1day2019Flash= math.sqrt(mean_squared_error(predictCBY1_2019Flash,WL2019Flash))\n","print('RMSE CB 1day 2019Flash = %.2f' %(rmseCB1day2019Flash))\n","\n","rmseCB3day2019Flash= math.sqrt(mean_squared_error(predictCBY3_2019Flash,WL2019Flash))\n","print('RMSE CB 3day 2019Flash = %.2f' %(rmseCB3day2019Flash))\n","\n","rmseCB5day2019Flash= math.sqrt(mean_squared_error(predictCBY5_2019Flash,WL2019Flash))\n","print('RMSE CB 5day 2019Flash = %.2f' %(rmseCB5day2019Flash))\n","\n","rmseCB7day2019Flash= math.sqrt(mean_squared_error(predictCBY7_2019Flash,WL2019Flash))\n","print('RMSE CB 7day 2019Flash = %.2f' %(rmseCB7day2019Flash))\n","\n","\n","predictLSTMY1_2019Flash=testpredictLSTM1[-1310-78+365+365:-1310+365+365].reshape(-1)\n","predictLSTMY3_2019Flash=testpredictLSTM3[-1310-78+365+365:-1310+365+365].reshape(-1)\n","predictLSTMY5_2019Flash=testpredictLSTM5[-1310-78+365+365:-1310+365+365].reshape(-1)\n","predictLSTMY7_2019Flash=testpredictLSTM7[-1310-78+365+365:-1310+365+365].reshape(-1)\n","\n","rmseLSTM1day2019Flash= math.sqrt(mean_squared_error(predictLSTMY1_2019Flash,WL2019Flash))\n","print('RMSE LSTM 1day 2019Flash = %.2f' %(rmseLSTM1day2019Flash))\n","\n","rmseLSTM3day2019Flash= math.sqrt(mean_squared_error(predictLSTMY3_2019Flash,WL2019Flash))\n","print('RMSE LSTM 3day 2019Flash = %.2f' %(rmseLSTM3day2019Flash))\n","\n","rmseLSTM5day2019Flash= math.sqrt(mean_squared_error(predictLSTMY5_2019Flash,WL2019Flash))\n","print('RMSE LSTM 5day 2019Flash = %.2f' %(rmseLSTM5day2019Flash))\n","\n","rmseLSTM7day2019Flash= math.sqrt(mean_squared_error(predictLSTMY7_2019Flash,WL2019Flash))\n","print('RMSE LSTM 7day 2019Flash = %.2f' %(rmseLSTM7day2019Flash))\n","\n","\n","rmse_2019Flash={'ANN':[rmseANN1day2019Flash,rmseANN3day2019Flash,rmseANN5day2019Flash,rmseANN7day2019Flash], 'RF':[rmseRF1day2019Flash,rmseRF3day2019Flash,rmseRF5day2019Flash,rmseRF7day2019Flash], 'CB':[rmseCB1day2019Flash,rmseCB3day2019Flash,rmseCB5day2019Flash,rmseCB7day2019Flash], 'LSTM': [rmseLSTM1day2019Flash,rmseLSTM3day2019Flash,rmseLSTM5day2019Flash,rmseLSTM7day2019Flash]}\n","df_rmse_2019Flash=pd.DataFrame(rmse_2019Flash)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OnElOtELHCiC"},"outputs":[],"source":["df_rmse_2019Flash"]},{"cell_type":"markdown","metadata":{"id":"IJG2dfRRHUC0"},"source":["## **Flash Flood 2020**"]},{"cell_type":"markdown","source":["we determine the water levels for Flash flood season 2020."],"metadata":{"id":"rggnPLZkNx4F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6K9852gAHTcv"},"outputs":[],"source":["WL2020Flash = testY1[-1310-78+366+365+365:-1310+366+365+365]\n","WL2020Flash"]},{"cell_type":"markdown","source":["Now we predict the water levels for the 2020 Flash flood period using our trained models for different lead times and calculate the RMSE values for each prediction.\n","\n","Finally we create a dataframe with the RMSE values for 2020 Flash flood"],"metadata":{"id":"5Lv5nvBtN5Wf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7OaDMtuH70e"},"outputs":[],"source":["predictANNY1_2020Flash=testpredictANN1[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","predictANNY3_2020Flash=testpredictANN3[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","predictANNY5_2020Flash=testpredictANN5[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","predictANNY7_2020Flash=testpredictANN7[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","\n","rmseANN1day2020Flash= math.sqrt(mean_squared_error(predictANNY1_2020Flash,WL2020Flash))\n","print('RMSE ANN 1day 2020Flash = %.2f' %(rmseANN1day2020Flash))\n","\n","rmseANN3day2020Flash= math.sqrt(mean_squared_error(predictANNY3_2020Flash,WL2020Flash))\n","print('RMSE ANN 3day 2020Flash = %.2f' %(rmseANN3day2020Flash))\n","\n","rmseANN5day2020Flash= math.sqrt(mean_squared_error(predictANNY5_2020Flash,WL2020Flash))\n","print('RMSE ANN 5day 2020Flash = %.2f' %(rmseANN5day2020Flash))\n","\n","rmseANN7day2020Flash= math.sqrt(mean_squared_error(predictANNY7_2020Flash,WL2020Flash))\n","print('RMSE ANN 7day 2020Flash = %.2f' %(rmseANN7day2020Flash))\n","\n","\n","predictRFY1_2020Flash=testpredictRF1[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","predictRFY3_2020Flash=testpredictRF3[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","predictRFY5_2020Flash=testpredictRF5[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","predictRFY7_2020Flash=testpredictRF7[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","\n","rmseRF1day2020Flash= math.sqrt(mean_squared_error(predictRFY1_2020Flash,WL2020Flash))\n","print('RMSE RF 1day 2020Flash = %.2f' %(rmseRF1day2020Flash))\n","\n","rmseRF3day2020Flash= math.sqrt(mean_squared_error(predictRFY3_2020Flash,WL2020Flash))\n","print('RMSE RF 3day 2020Flash = %.2f' %(rmseRF3day2020Flash))\n","\n","rmseRF5day2020Flash= math.sqrt(mean_squared_error(predictRFY5_2020Flash,WL2020Flash))\n","print('RMSE RF 5day 2020Flash = %.2f' %(rmseRF5day2020Flash))\n","\n","rmseRF7day2020Flash= math.sqrt(mean_squared_error(predictRFY7_2020Flash,WL2020Flash))\n","print('RMSE RF 7day 2020Flash = %.2f' %(rmseRF7day2020Flash))\n","\n","\n","predictCBY1_2020Flash=testpredictCB1[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","predictCBY3_2020Flash=testpredictCB3[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","predictCBY5_2020Flash=testpredictCB5[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","predictCBY7_2020Flash=testpredictCB7[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","\n","rmseCB1day2020Flash= math.sqrt(mean_squared_error(predictCBY1_2020Flash,WL2020Flash))\n","print('RMSE CB 1day 2020Flash = %.2f' %(rmseCB1day2020Flash))\n","\n","rmseCB3day2020Flash= math.sqrt(mean_squared_error(predictCBY3_2020Flash,WL2020Flash))\n","print('RMSE CB 3day 2020Flash = %.2f' %(rmseCB3day2020Flash))\n","\n","rmseCB5day2020Flash= math.sqrt(mean_squared_error(predictCBY5_2020Flash,WL2020Flash))\n","print('RMSE CB 5day 2020Flash = %.2f' %(rmseCB5day2020Flash))\n","\n","rmseCB7day2020Flash= math.sqrt(mean_squared_error(predictCBY7_2020Flash,WL2020Flash))\n","print('RMSE CB 7day 2020Flash = %.2f' %(rmseCB7day2020Flash))\n","\n","\n","predictLSTMY1_2020Flash=testpredictLSTM1[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","predictLSTMY3_2020Flash=testpredictLSTM3[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","predictLSTMY5_2020Flash=testpredictLSTM5[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","predictLSTMY7_2020Flash=testpredictLSTM7[-1310-78+365+365+366:-1310+365+365+366].reshape(-1)\n","\n","rmseLSTM1day2020Flash= math.sqrt(mean_squared_error(predictLSTMY1_2020Flash,WL2020Flash))\n","print('RMSE LSTM 1day 2020Flash = %.2f' %(rmseLSTM1day2020Flash))\n","\n","rmseLSTM3day2020Flash= math.sqrt(mean_squared_error(predictLSTMY3_2020Flash,WL2020Flash))\n","print('RMSE LSTM 3day 2020Flash = %.2f' %(rmseLSTM3day2020Flash))\n","\n","rmseLSTM5day2020Flash= math.sqrt(mean_squared_error(predictLSTMY5_2020Flash,WL2020Flash))\n","print('RMSE LSTM 5day 2020Flash = %.2f' %(rmseLSTM5day2020Flash))\n","\n","rmseLSTM7day2020Flash= math.sqrt(mean_squared_error(predictLSTMY7_2020Flash,WL2020Flash))\n","print('RMSE LSTM 7day 2020Flash = %.2f' %(rmseLSTM7day2020Flash))\n","\n","\n","rmse_2020Flash={'ANN':[rmseANN1day2020Flash,rmseANN3day2020Flash,rmseANN5day2020Flash,rmseANN7day2020Flash], 'RF':[rmseRF1day2020Flash,rmseRF3day2020Flash,rmseRF5day2020Flash,rmseRF7day2020Flash], 'CB':[rmseCB1day2020Flash,rmseCB3day2020Flash,rmseCB5day2020Flash,rmseCB7day2020Flash], 'LSTM': [rmseLSTM1day2020Flash,rmseLSTM3day2020Flash,rmseLSTM5day2020Flash,rmseLSTM7day2020Flash]}\n","df_rmse_2020Flash=pd.DataFrame(rmse_2020Flash)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iKMwYStfH9DG"},"outputs":[],"source":["df_rmse_2020Flash"]},{"cell_type":"markdown","metadata":{"id":"pBTMT7RxIdYv"},"source":["## **Flash Flood df**"]},{"cell_type":"markdown","source":["Now we create a dataframe and merge all the RMSE values for the flash flood events."],"metadata":{"id":"M8gbLI_LOQ6b"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"x7jDPs7cIb3w"},"outputs":[],"source":["rmse_Flash = pd.concat([df_rmse_2017Flash, df_rmse_2018Flash, df_rmse_2019Flash, df_rmse_2020Flash ],axis=1)\n","rmse_Flash"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wuz9WLMAKVfd"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"_vMsKSr-ioZa"},"source":["# **Plots**"]},{"cell_type":"markdown","source":["The following are codes for scatter plots for predicted vs actual water levels for different models at differnt lead times, followed by time series plots for Monsoon floods and Flash flood events for dofferent models at different leadtimes."],"metadata":{"id":"Y-ElYYAnOi29"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_74C-rXqIgW"},"outputs":[],"source":["import matplotlib.lines as mlines\n","import matplotlib.transforms as mtransforms\n","from matplotlib.pyplot import figure\n","import os\n","import matplotlib.font_manager\n","dpi = 600\n","sizeX, sizeY = 6, 6\n","figure(figsize=(6, 6), dpi=600)"]},{"cell_type":"code","source":["import matplotlib.lines as mlines\n","import matplotlib.transforms as mtransforms\n","from matplotlib.pyplot import figure\n","import os\n","import matplotlib.font_manager\n","\n","for state in ['train','val','test']:\n","  for n in [1,3,5,7]:\n","    fig, ax = plt.subplots(2, 2)\n","    figure(figsize=(15, 15), dpi=600)\n","    for model in ['ANN','RF','CB','LSTM']:\n","      if model == 'ANN':\n","        color, ab,cd,axis, xlabel, ylabel= 'green',0,0,'on','','Predicted WL (m)'\n","      elif model == 'RF':\n","        color,ab,cd,axis, xlabel, ylabel = 'red',0,1,'on','',''\n","      elif model == 'CB':\n","        color,ab,cd ,axis, xlabel, ylabel= 'blue',1,0,'on','Observed WL (m)','Predicted WL (m)'\n","      elif model == 'LSTM':\n","        color,ab,cd,axis, xlabel, ylabel= 'magenta',1,1,'on','Observed WL (m)',''\n","      figname = \"fig_\"+state+model+str(n)\n","      axname = \"ax_\"+state+model+str(n)\n","      print(figname)\n","      print(axname)\n","      #figname, axname = plt.subplots()\n","      plt.style.use('seaborn-whitegrid')\n","      if model == 'LSTM':\n","        X=globals()[state+\"Y_\"+model+str(n)]\n","      else:\n","        X=globals()[state+\"Y\"+str(n)]\n","      \n","      Y=globals()[state+\"predict\"+model+str(n)]\n","      ax[ab,cd].scatter(X,Y, c=color, linewidth=1, edgecolor='black', alpha=0.5)\n","\n","\n","      ax[ab,cd].set_xlabel(xlabel, fontsize = 9)\n","      ax[ab,cd].set_ylabel(ylabel, fontsize = 9)\n","\n","      ax[ab,cd].axis(axis)\n","      if model == 'ANN': ax[ab,cd].set_xticks([])\n","      elif model == 'RF': ax[ab,cd].set_xticks([])\n","\n","      ax[ab,cd].plot([0,1],[0,1], transform=ax[ab,cd].transAxes, c='black', linewidth=0.5, alpha=0.5)\n","\n","      plt.rcParams[\"font.family\"] = \"Times New Roman\"\n","      plt.rcParams[\"font.size\"] = 6\n","      \n","      if model == \"ANN\": modelname=\"DNN\"\n","      else: modelname=model\n","\n","      ax[ab,cd].set_title(state+\" \"+modelname+\" Comb 1  T+\"+str(n), fontsize = 9)\n","\n","      #transform = axname.transAxes\n","      #line.set_transform(transform)\n","      #axname.add_line(line)\n","\n","      rmse =globals() [state+'Score'+model+str(n)]\n","      r2= globals() [state+'r2_'+model+str(n)]\n","      #print(rmse)\n","      #print(r2)\n","      \n","      text1= \"RMSE = \"+str(float(\"{:.2f}\".format(rmse)))+\" (m)\"\n","      text2= \"R$^2$ = \"+str(float(\"{:.3f}\".format(r2)))\n","\n","      ax[ab,cd].text(2.5,14,text1, fontsize = 9)\n","      ax[ab,cd].text(2.5,12,text2, fontsize = 9)\n","\n","      ax[ab,cd].set_xlim([2, 16])\n","      ax[ab,cd].set_ylim([2, 16])\n","\n","      figure(figsize=(6, 6), dpi=600)\n","\n","    plt.tight_layout()\n","    #plt.subplots_adjust(wspace=0.4, hspace=1)\n","    plt.show()\n","\n","    dir=\"/content/drive/MyDrive/Thesis/Plots/\"+vars+\"/Scatter_Plots/\"+state+\" Comb 1  T+\"+str(n)+\".jpg\"\n","    print(dir)\n","\n","    #fig.savefig(f\"{dir}\", dpi=600)"],"metadata":{"id":"-eWGsoVTABqu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A1X-U7YDl-y3"},"source":["## **WL plots**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vVvC93domCUv"},"outputs":[],"source":["dates = dataframe['Date']\n","dates_monsoon = dates[-1310:-1173]\n","dates_flash = dates[-1310-78:-1310]\n","dates_monsoon\n","dates_flash"]},{"cell_type":"markdown","metadata":{"id":"sm3ACmwMpoP9"},"source":["### **Monsoon Plots**"]},{"cell_type":"code","source":["import matplotlib.lines as mlines\n","import matplotlib.transforms as mtransforms\n","from matplotlib.pyplot import figure\n","import os\n","import matplotlib.font_manager"],"metadata":{"id":"D7ybOQ3mVsmE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMeo36Hhpm_S"},"outputs":[],"source":["for year in ['2017','2018','2019','2020']:\n","  fig,ax = plt.subplots(2,2)\n","  for n in [1,3,5,7]:\n","      if n==1: p,q,xlabel,ylabel=0,0,'',''\n","      if n==3: p,q,xlabel,ylabel=0,1,'',''\n","      if n==5: p,q,xlabel,ylabel=1,0,'Date','WL(m)'\n","      if n==7: p,q,xlabel,ylabel=1,1,'Date','WL(m)'\n","      figname= str(year)+\" Monsoon Comb 1 T+\"+str(n)\n","      print(figname)\n","      x= dates_monsoon\n","      for model in ['ANN','RF','CB','LSTM']:\n","          if model == 'ANN':\n","            color = 'green'\n","            modelname=\"DNN\"\n","          elif model == 'RF':\n","            color = 'red'\n","            modelname=model\n","          elif model == 'CB':\n","            color = 'blue'\n","            modelname=model\n","          elif model == 'LSTM':\n","            color = 'magenta'\n","            modelname=model\n","\n","          y = \"predict\"+model+\"Y\"+str(n)+\"_\"+str(year)+\"Monsoon\"\n","          print(y)\n","          ax[p,q].plot(dates_monsoon,(globals()[y]),linestyle='solid', linewidth =1, color=color, label = modelname)\n","        \n","          ax[p,q].set_xlabel('Date',fontsize=8)\n","          ax[p,q].set_ylabel('WL(m)',fontsize=8)\n","          ax[p,q].grid(False)\n","        \n","\n","      ax[p,q].plot(dates_monsoon,globals()[\"WL\"+str(year)+\"Monsoon\"],linestyle='solid', linewidth =2, color='black', label = 'Observed')\n","      ax[p,q].set_title(figname, fontsize=9)\n","      if n==1: ax[p,q].set_xticks([])\n","      elif n==3:ax[p,q].set_xticks([])\n","      start, end = ax[p,q].get_xlim()\n","      ax[p,q].xaxis.set_ticks(np.arange(start, end, 30))\n","\n","      ax[p,q].legend(fontsize=6)\n","      plt.rcParams[\"font.family\"] = \"Times New Roman\"\n","      plt.rcParams[\"font.size\"] = 6\n","    \n","      plt.gcf().autofmt_xdate()\n","      ax[p,q].set_ylim(5,16)\n","\n","\n","  plt.tight_layout()\n","  \n","  dir=\"/content/drive/MyDrive/Thesis/Plots/\"+vars+\"/WL_Plots/\"+figname+\".jpg\"\n","  print(dir)\n","\n","  #plt.savefig(f\"{dir}\", dpi =600)\n","  plt.show()\n","\n","  \n","\n","\n","\n"]},{"cell_type":"markdown","source":["### **Flash Plots**"],"metadata":{"id":"OkhNXBc2kWP0"}},{"cell_type":"code","source":["for year in ['2017','2018','2019','2020']:\n","  fig,ax = plt.subplots(2,2)\n","  for n in [1,3,5,7]:\n","      if n==1: p,q,xlabel,ylabel=0,0,'',''\n","      if n==3: p,q,xlabel,ylabel=0,1,'',''\n","      if n==5: p,q,xlabel,ylabel=1,0,'Date','WL(m)'\n","      if n==7: p,q,xlabel,ylabel=1,1,'Date','WL(m)'\n","      figname= str(year)+\" Flash Comb 1 T+\"+str(n)\n","      print(figname)\n","      x= dates_flash\n","      for model in ['ANN','RF','CB','LSTM']:\n","          if model == 'ANN':\n","            color = 'green'\n","            modelname=\"DNN\"\n","          elif model == 'RF':\n","            color = 'red'\n","            modelname=model\n","          elif model == 'CB':\n","            color = 'blue'\n","            modelname=model\n","          elif model == 'LSTM':\n","            color = 'magenta'\n","            modelname=model\n","\n","          y = \"predict\"+model+\"Y\"+str(n)+\"_\"+str(year)+\"Flash\"\n","          print(y)\n","          ax[p,q].plot(x,(globals()[y]),linestyle='solid', linewidth =1, color=color, label = modelname)\n","        \n","          ax[p,q].set_xlabel('Date',fontsize=8)\n","          ax[p,q].set_ylabel('WL(m)',fontsize=8)\n","          ax[p,q].grid(False)\n","        \n","\n","      ax[p,q].plot(x,globals()[\"WL\"+str(year)+\"Flash\"],linestyle='solid', linewidth =2, color='black', label = 'Observed')\n","      ax[p,q].set_title(figname, fontsize=9)\n","      if n==1: ax[p,q].set_xticks([])\n","      elif n==3:ax[p,q].set_xticks([])\n","      start, end = ax[p,q].get_xlim()\n","      ax[p,q].xaxis.set_ticks(np.arange(start, end, 15))\n","\n","      ax[p,q].legend(fontsize=6)\n","      plt.rcParams[\"font.family\"] = \"Times New Roman\"\n","      plt.rcParams[\"font.size\"] = 6\n","    \n","      plt.gcf().autofmt_xdate()\n","      ax[p,q].set_ylim(2,16)\n","\n","\n","  \n","  dir=\"/content/drive/MyDrive/Thesis/Plots/\"+vars+\"/WL_Plots/\"+figname+\".jpg\"\n","  print(dir)\n","  plt.tight_layout()\n","\n","  #plt.savefig(f\"{dir}\", dpi=600)\n","  plt.show()\n","\n"],"metadata":{"id":"RUY3rDro7oj7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Finally, for a different combination of variables, change the value for comb at the begining and repeat the entire process. Thank you. **"],"metadata":{"id":"CcqaaDx3PIz0"}}],"metadata":{"colab":{"collapsed_sections":["Gu1nKaSwx2mZ","W75Mp7Lex8Jp","-4eSbhC_9SbF","mELZXJHj8NsT","i5QGKu5C8T8P","874FOQer8ZO3","Ny_foq8n8f5e","5yGBULR48mr2","MCO7cvXrEYnb","AMwvm-HH-kyw","zrKFVWD_-2gC","bFyjzLk6bfwx","2X8-0CAcbrhC","UK1aOSw-b6Tp","1uFfbmXUcA1F","aiIAMF7g0wOK","ZGlNu-oXXWM-","sLMqAK3tRtXm","w77B3Kg8Ry3E","2gu0a-DJUrJ9","7MunhshHcNAt","G9EWYyg1Px1C","EAnR8ZC_LJcT","kFztqopWCzPg","ZlvyPsZQMwN6","fmr3sl9iMMNV","G76BVAGRLP9P","MxBRdlJeIJIG","-SW639CNCz5E","mBvLE4sFFsbX","oP-Ayqj0GlME","IJG2dfRRHUC0"],"name":"Alvee_BSc_Thesis_Code.ipynb","provenance":[{"file_id":"1RD2LbOFSWneLROR5TVaQeBPJI71vz-zN","timestamp":1652161982811},{"file_id":"1YzAqhm_d0T7T55Dh1wKZRKNuobD9mBbK","timestamp":1652161003793},{"file_id":"1Rl9vag7dmGmhX7DfzANI4qN9dg6bjGWF","timestamp":1652159008108},{"file_id":"1TDpy0AD-5d4S5I3D3gL3_K_jC7_R3J4Z","timestamp":1651691022383},{"file_id":"13s9IBI3jDn54lO_J9yTV7X9lm__GoHBd","timestamp":1651389234390},{"file_id":"1K6W-hxBRjsvt7EeBQJUpF1PWFeqt3N5z","timestamp":1651388527883}],"authorship_tag":"ABX9TyONd1q6y7Sv0mvf4lWR3Xui"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}